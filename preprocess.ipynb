{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Worked on by: Meena Hari and Tarini Singh.\n",
    "\n",
    "We perform data preprocessing using KNearestNeighbors.\n",
    "66 new features are generated.\n",
    "\n",
    "Trained a 1 layer ANN with transformed, higher dimensional \n",
    "dataset (each input consists of the raw board representaion \n",
    "(list of integers from 1 - 16) plus 66 newly generated features).\n",
    "\n",
    "In prog.\n",
    "\n",
    "'''\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from tqdm import tqdm\n",
    "import keras.backend as K\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Conv2D, Flatten, Input\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from keras.models import load_model\n",
    "import keras.losses\n",
    "\n",
    "from constants import * \n",
    "from heuristic import *\n",
    "from io_help import *\n",
    "from solver import *\n",
    "\n",
    "def load_data(file_name):\n",
    "\t\"\"\"\n",
    "\tThis function reads in training data from a file and returns \n",
    "\tthe boards in X and their labels in Y as a tuple. \n",
    "\t\"\"\"\n",
    "\tfile = open(file_name, \"r\")\n",
    "\tX = []\n",
    "\tY = []\n",
    "    \n",
    "\tfor string in file: \n",
    "\t\t(board, dist) = string_to_board_and_dist(string)\n",
    "\t\tX.append(np.asarray(board).flatten())\n",
    "\t\tY.append(dist)\n",
    "        \n",
    "\tfile.close()\n",
    "\tX_train = np.asarray(X)\n",
    "\tY_train = np.asarray(Y)\n",
    "\treturn(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset. \n",
    "# X: board inputs, Y: true output.\n",
    "(X_train,Y_train) = load_data('Uncombined Data Files/meena_5_19_2020_93844.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generates additional features.\n",
    "# X: the input data file.\n",
    "# X_train: the original training data file (not transformed).\n",
    "def gen_features (X, X_train, knn_model):\n",
    "    data_arr = np.zeros([len(X), 16*2*2 + 2])\n",
    "    pred = knn_model.kneighbors(X)\n",
    "    \n",
    "    for i in tqdm(range(len(X))):\n",
    "        row = X[i]\n",
    "        # Grabs the rows in X corresponding to 50 nearest neighbors of X[i].\n",
    "        # pred[1][i] contains a list of the indices of the 50 nearest neighbors.\n",
    "        data = X_train[pred[1][i]]\n",
    "        # Divide X[i] by each of its neighbors. div should be a \n",
    "        # 50 x 16 matrix, i.e. div[j] = X[i] / X[j].\n",
    "        div = (row / data)\n",
    "        # Subtract X[i] by each of its neighbors. diff should be a \n",
    "        # 50 x 16 dimension matrix.\n",
    "        diff = (row - data)\n",
    "        # concat is a 50 x 32 matrix.\n",
    "        concat = np.concatenate([div, diff], axis = 1)\n",
    "        # means is a 50 x 32 matrix.\n",
    "        # std is a 50 x 32 matrix.\n",
    "        means, stds = np.nanmean(concat, axis = 0), np.nanstd(concat, axis = 0)\n",
    "        # Populate data_arr with newly generated features.\n",
    "        data_arr[i, :len(means)] = means\n",
    "        data_arr[i, len(means):len(means) + len(stds)] = stds\n",
    "        data_arr[i, -1] = np.nanmean(pred[0][i])\n",
    "        data_arr[i, -2] = np.nanstd(pred[0][i])\n",
    "    # Concatenate generated features to the original dataset.\n",
    "    return np.concatenate([X, data_arr], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 93844/93844 [00:23<00:00, 4053.81it/s]\n"
     ]
    }
   ],
   "source": [
    "knn_model = NearestNeighbors(n_neighbors=50, n_jobs = -1).fit(X_train,Y_train)\n",
    "X_train_2 = gen_features(X_train, X_train, knn_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shift_mse(y_true, y_pred):\n",
    "    \"\"\"custom loss functions\"\"\"\n",
    "    loss = (1 + 1/ (1 + K.exp(-(y_pred - y_true)))) * K.square(y_pred - y_true)\n",
    "    loss = K.mean(loss, axis = 1)\n",
    "    return loss\n",
    "keras.losses.shift_mse = shift_mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "93844/93844 [==============================] - 3s 27us/step - loss: 14.7790 - accuracy: 0.1707\n",
      "Epoch 2/20\n",
      "93844/93844 [==============================] - 2s 27us/step - loss: 11.9584 - accuracy: 0.2146\n",
      "Epoch 3/20\n",
      "93844/93844 [==============================] - 3s 32us/step - loss: 11.0625 - accuracy: 0.2418\n",
      "Epoch 4/20\n",
      "93844/93844 [==============================] - 2s 25us/step - loss: 10.5533 - accuracy: 0.2563: 1s \n",
      "Epoch 5/20\n",
      "93844/93844 [==============================] - 3s 29us/step - loss: 10.1694 - accuracy: 0.2688\n",
      "Epoch 6/20\n",
      "93844/93844 [==============================] - 3s 28us/step - loss: 10.0075 - accuracy: 0.2732\n",
      "Epoch 7/20\n",
      "93844/93844 [==============================] - 3s 28us/step - loss: 9.7009 - accuracy: 0.2812\n",
      "Epoch 8/20\n",
      "93844/93844 [==============================] - 3s 27us/step - loss: 9.5571 - accuracy: 0.2868\n",
      "Epoch 9/20\n",
      "93844/93844 [==============================] - 2s 25us/step - loss: 9.3717 - accuracy: 0.2902\n",
      "Epoch 10/20\n",
      "93844/93844 [==============================] - 2s 25us/step - loss: 9.1949 - accuracy: 0.2949\n",
      "Epoch 11/20\n",
      "93844/93844 [==============================] - 3s 27us/step - loss: 9.0381 - accuracy: 0.3031 0s - loss: 9.0484 - accuracy: \n",
      "Epoch 12/20\n",
      "93844/93844 [==============================] - 2s 25us/step - loss: 8.9200 - accuracy: 0.3062 \n",
      "Epoch 13/20\n",
      "93844/93844 [==============================] - 2s 25us/step - loss: 8.7827 - accuracy: 0.3065\n",
      "Epoch 14/20\n",
      "93844/93844 [==============================] - 2s 26us/step - loss: 8.7137 - accuracy: 0.3126\n",
      "Epoch 15/20\n",
      "93844/93844 [==============================] - 3s 31us/step - loss: 8.5556 - accuracy: 0.3136\n",
      "Epoch 16/20\n",
      "93844/93844 [==============================] - 3s 27us/step - loss: 8.4726 - accuracy: 0.3147\n",
      "Epoch 17/20\n",
      "93844/93844 [==============================] - 2s 24us/step - loss: 8.3811 - accuracy: 0.3188 0s - los\n",
      "Epoch 18/20\n",
      "93844/93844 [==============================] - 3s 27us/step - loss: 8.3000 - accuracy: 0.3169\n",
      "Epoch 19/20\n",
      "93844/93844 [==============================] - 2s 24us/step - loss: 8.2187 - accuracy: 0.3183 1s - loss: 8.1 - ETA: 0s - loss: - ETA: 0s - loss: 8.2350 - accuracy: \n",
      "Epoch 20/20\n",
      "93844/93844 [==============================] - 2s 25us/step - loss: 8.1614 - accuracy: 0.3214\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1057682e8>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build Model\n",
    "model = Sequential()\n",
    "\n",
    "# Input Layer\n",
    "model.add(Dense(units=(16*2*2+2+16), input_dim=(16*2*2+2+16), activation='relu'))\n",
    "model.add(Dropout(0.1))\n",
    "\n",
    "# Hidden Layers\n",
    "model.add(Dense(units=66+16, activation='relu'))\n",
    "\n",
    "# Output Layer\n",
    "model.add(Dense(units=1, activation='linear'))\n",
    "\n",
    "# Define the optimizer and loss function\n",
    "#model.compile(optimizer='adam', loss='mse', metrics=['accuracy'])\n",
    "model.compile(optimizer='adam', loss=shift_mse, metrics=['accuracy'])\n",
    "\n",
    "# You can also define a custom loss function\n",
    "# model.compile(optimizer='adam', loss=custom_loss)\n",
    "\n",
    "# Train \n",
    "model.fit(X_train_2, Y_train, epochs=20)\n",
    "\n",
    "# Test\n",
    "#score = model.evaluate(X_test, Y_test)\n",
    "\n",
    "#print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10047/10047 [00:02<00:00, 4335.15it/s]\n"
     ]
    }
   ],
   "source": [
    "# Rough Testing\n",
    "\n",
    "# Load test dataset. \n",
    "# X_test: board inputs, Y_test: true output.\n",
    "(X_test,Y_test) = load_data('Uncombined Data Files/Yasmin_5_19_10048.txt')\n",
    "\n",
    "# Transform X_test to higher dimension.\n",
    "X_test_2 = gen_features (X_test, X_train, knn_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10047/10047 [00:17<00:00, 558.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ TRUCATION: ------ \n",
      "\n",
      "Avg distance overestimated:  2.732376530181511\n",
      "Avg distance underestimated:  2.1070591299817663\n",
      "E_admiss:  0.23579177864039016\n",
      "E_out:  0.7764506817955609\n",
      "------ ROUNDED: ------ \n",
      "\n",
      "Avg distance overestimated:  2.6403682\n",
      "Avg distance underestimated:  1.8386867\n",
      "E_admiss:  0.3027769483427889\n",
      "E_out:  0.6852791878172588\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dist_over_i = []\n",
    "misclass_i = 0\n",
    "dist_under_i = []\n",
    "\n",
    "dist_over_r = []\n",
    "misclass_r = 0\n",
    "dist_under_r = []\n",
    "\n",
    "for i in tqdm(range(len(X_test))):\n",
    "    nn_heur_i = int(model.predict(X_test_2[i:(i+1),:]))\n",
    "    nn_heur_r = np.around(model.predict(X_test_2[i:(i+1),:]))\n",
    "    man_heur = manhattan(X_test[i].reshape(SIZE,SIZE), model)\n",
    "    y = Y_test[i]\n",
    "    \n",
    "    ### TRUNCATE ###\n",
    "    if (nn_heur_i > y):\n",
    "        dist_over_i.append(nn_heur_i - y)\n",
    "    \n",
    "    if (nn_heur_i <= y):\n",
    "        dist_under_i.append(y - nn_heur_i)\n",
    "    \n",
    "    if (nn_heur_i != y):\n",
    "        misclass_i += 1\n",
    "        \n",
    "    ##### ROUND ##### \n",
    "    if (nn_heur_r > y):\n",
    "        dist_over_r.append(nn_heur_r - y)\n",
    "    \n",
    "    if (nn_heur_r <= y):\n",
    "        dist_under_r.append(y - nn_heur_r)\n",
    "    \n",
    "    if (nn_heur_r != y):\n",
    "        misclass_r += 1\n",
    "    \n",
    "avg_dist_over_i = np.mean(np.asarray(dist_over_i))\n",
    "avg_dist_under_i = np.mean(np.asarray(dist_under_i))\n",
    "out_sample_error_i = misclass_i / len(X_test)\n",
    "\n",
    "avg_dist_over_r = np.mean(np.asarray(dist_over_r))\n",
    "avg_dist_under_r = np.mean(np.asarray(dist_under_r))\n",
    "out_sample_error_r = misclass_r / len(X_test)\n",
    " \n",
    "print(\"------ TRUCATION: ------\")\n",
    "print(\"Avg distance overestimated: \", avg_dist_over_i)\n",
    "print(\"Avg distance underestimated: \", avg_dist_under_i)\n",
    "print(\"E_admiss: \", len(dist_over_i)/len(X_test))\n",
    "print(\"E_out: \", out_sample_error_i)\n",
    "\n",
    "print(\"------ ROUNDED: ------\")\n",
    "print(\"Avg distance overestimated: \", avg_dist_over_r)\n",
    "print(\"Avg distance underestimated: \", avg_dist_under_r)\n",
    "print(\"E_admiss: \", len(dist_over_r)/len(X_test))\n",
    "print(\"E_out: \", out_sample_error_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40360/40360 [00:09<00:00, 4309.86it/s]\n"
     ]
    }
   ],
   "source": [
    "# DON'T HAVE TO RUN THIS CELL AGAIN, only to transform Yasmin_5_16_40360.txt.\n",
    "\n",
    "(X,Y) = load_data('Uncombined Data Files/Yasmin_5_16_40360.txt')\n",
    "knn_model_all = NearestNeighbors(n_neighbors=50, n_jobs = -1).fit(X,Y)\n",
    "X_2 = gen_features(X, X, knn_model_all)\n",
    "X_Y = np.column_stack((X_2, Y))\n",
    "np.savetxt(\"Yasmin_40360_50knn_Trans.csv\", X_Y, delimiter=',')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
