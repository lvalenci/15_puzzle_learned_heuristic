{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Worked on by: Meena Hari and Tarini Singh.\n",
    "\n",
    "We perform data preprocessing using KNearestNeighbors.\n",
    "66 new features are generated.\n",
    "\n",
    "Trained a 1 layer ANN with transformed, higher dimensional \n",
    "dataset (each input consists of the raw board representaion \n",
    "(list of integers from 1 - 16) plus 66 newly generated features).\n",
    "\n",
    "In prog.\n",
    "\n",
    "'''\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from tqdm import tqdm\n",
    "import keras.backend as K\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Conv2D, Flatten, Input\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from keras.models import load_model\n",
    "import keras.losses\n",
    "\n",
    "from constants import * \n",
    "from heuristic import *\n",
    "from io_help import *\n",
    "from solver import *\n",
    "\n",
    "def load_data(file_name):\n",
    "\t\"\"\"\n",
    "\tThis function reads in training data from a file and returns \n",
    "\tthe boards in X and their labels in Y as a tuple. \n",
    "\t\"\"\"\n",
    "\tfile = open(file_name, \"r\")\n",
    "\n",
    "\tX = []\n",
    "\tY = []\n",
    "\n",
    "\tfor string in file: \n",
    "\t\t(board, dist) = string_to_board_and_dist(string)\n",
    "\t\tX.append(np.asarray(board).flatten())\n",
    "\t\tY.append(dist)\n",
    "    \n",
    "\n",
    "\tfile.close()\n",
    "\n",
    "\tX_train = np.asarray(X)\n",
    "\tY_train = np.asarray(Y)\n",
    "    \n",
    "\treturn(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset. \n",
    "# X: board inputs, Y: true output.\n",
    "(X_train,Y_train) = load_data('Uncombined Data Files/meena_5_19_2020_93844.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_model = NearestNeighbors(n_neighbors=50, n_jobs = -1).fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_features (X, X_train):\n",
    "    data_arr = np.zeros([len(X), 16*2*2 + 2])\n",
    "    pred = knn_model.kneighbors(X)\n",
    "    \n",
    "    for i in tqdm(range(len(X))):\n",
    "        row = X[i]\n",
    "        # Grabs the rows in X corresponding to 50 nearest neighbors of X[i].\n",
    "        # pred[1][i] contains a list of the indices of the 50 nearest neighbors.\n",
    "        data = X_train[pred[1][i]]\n",
    "        # Divide X[i] by each of its neighbors. div should be a \n",
    "        # 50 x 16 matrix, i.e. div[j] = X[i] / X[j].\n",
    "        div = (row / data)\n",
    "        # Subtract X[i] by each of its neighbors. diff should be a \n",
    "        # 50 x 16 dimension matrix.\n",
    "        diff = (row - data)\n",
    "        # concat is a 50 x 32 matrix.\n",
    "        concat = np.concatenate([div, diff], axis = 1)\n",
    "        # means is a 50 x 32 matrix.\n",
    "        # std is a 50 x 32 matrix.\n",
    "        means, stds = np.nanmean(concat, axis = 0), np.nanstd(concat, axis = 0)\n",
    "        # Populate data_arr with newly generated features.\n",
    "        data_arr[i, :len(means)] = means\n",
    "        data_arr[i, len(means):len(means) + len(stds)] = stds\n",
    "        data_arr[i, -1] = np.nanmean(pred[0][i])\n",
    "        data_arr[i, -2] = np.nanstd(pred[0][i])\n",
    "    # Concatenate generated features to the original dataset.\n",
    "    return np.concatenate([X, data_arr], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 93844/93844 [00:31<00:00, 2977.33it/s]\n"
     ]
    }
   ],
   "source": [
    "X_train_2 = gen_features(X_train, X_train)\n",
    "# Following output makes sense because the first couple of rows represent boards \n",
    "# close to the solution (based on the way we ordered our training sets... first data points in X\n",
    "# are 1, 2, and 3 moves away from solution), so div will be 1 for most entries, diff will be 0 for most\n",
    "# entries, and so on. The last couple rows will represent boards farther from the solution, so the generated \n",
    "# features are not clean numbers.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shift_mse(y_true, y_pred):\n",
    "    \"\"\"custom loss functions\"\"\"\n",
    "    loss = (1 + 1/ (1 + K.exp(-(y_pred - y_true)))) * K.square(y_pred - y_true)\n",
    "    loss = K.mean(loss, axis = 1)\n",
    "    return loss\n",
    "keras.losses.shift_mse = shift_mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "93844/93844 [==============================] - 5s 52us/step - loss: 15.1016 - accuracy: 0.1668\n",
      "Epoch 2/20\n",
      "93844/93844 [==============================] - 4s 46us/step - loss: 11.8962 - accuracy: 0.2121\n",
      "Epoch 3/20\n",
      "93844/93844 [==============================] - 4s 44us/step - loss: 11.1342 - accuracy: 0.2375\n",
      "Epoch 4/20\n",
      "93844/93844 [==============================] - 4s 44us/step - loss: 10.6348 - accuracy: 0.2547: 0s - loss: 10.6297 - accuracy: 0.2\n",
      "Epoch 5/20\n",
      "93844/93844 [==============================] - 4s 44us/step - loss: 10.2692 - accuracy: 0.2656\n",
      "Epoch 6/20\n",
      "93844/93844 [==============================] - 5s 53us/step - loss: 9.9314 - accuracy: 0.2700\n",
      "Epoch 7/20\n",
      "93844/93844 [==============================] - 4s 47us/step - loss: 9.6447 - accuracy: 0.2799\n",
      "Epoch 8/20\n",
      "93844/93844 [==============================] - 5s 48us/step - loss: 9.3896 - accuracy: 0.2867\n",
      "Epoch 9/20\n",
      "93844/93844 [==============================] - 4s 48us/step - loss: 9.1898 - accuracy: 0.2899\n",
      "Epoch 10/20\n",
      "93844/93844 [==============================] - 4s 48us/step - loss: 9.0266 - accuracy: 0.2940\n",
      "Epoch 11/20\n",
      "93844/93844 [==============================] - 5s 49us/step - loss: 8.8174 - accuracy: 0.2995\n",
      "Epoch 12/20\n",
      "93844/93844 [==============================] - 5s 49us/step - loss: 8.7445 - accuracy: 0.3032\n",
      "Epoch 13/20\n",
      "93844/93844 [==============================] - 5s 48us/step - loss: 8.5472 - accuracy: 0.3084\n",
      "Epoch 14/20\n",
      "93844/93844 [==============================] - 5s 55us/step - loss: 8.5257 - accuracy: 0.3088\n",
      "Epoch 15/20\n",
      "93844/93844 [==============================] - 5s 54us/step - loss: 8.3988 - accuracy: 0.3128\n",
      "Epoch 16/20\n",
      "93844/93844 [==============================] - 5s 55us/step - loss: 8.3172 - accuracy: 0.3162\n",
      "Epoch 17/20\n",
      "93844/93844 [==============================] - 4s 48us/step - loss: 8.2423 - accuracy: 0.3179\n",
      "Epoch 18/20\n",
      "93844/93844 [==============================] - 4s 46us/step - loss: 8.1909 - accuracy: 0.3176\n",
      "Epoch 19/20\n",
      "93844/93844 [==============================] - 4s 48us/step - loss: 8.1209 - accuracy: 0.3181 0s - loss: 8.1252 - \n",
      "Epoch 20/20\n",
      "93844/93844 [==============================] - 5s 50us/step - loss: 8.0341 - accuracy: 0.3224\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x104b58c88>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build Model\n",
    "model = Sequential()\n",
    "\n",
    "# Input Layer\n",
    "model.add(Dense(units=(16*2*2+2+16), input_dim=(16*2*2+2+16), activation='relu'))\n",
    "model.add(Dropout(0.1))\n",
    "\n",
    "# Hidden Layers\n",
    "model.add(Dense(units=66+16, activation='relu'))\n",
    "\n",
    "# Output Layer\n",
    "model.add(Dense(units=1, activation='linear'))\n",
    "\n",
    "# Define the optimizer and loss function\n",
    "#model.compile(optimizer='adam', loss='mse', metrics=['accuracy'])\n",
    "model.compile(optimizer='adam', loss=shift_mse, metrics=['accuracy'])\n",
    "\n",
    "# You can also define a custom loss function\n",
    "# model.compile(optimizer='adam', loss=custom_loss)\n",
    "\n",
    "# Train \n",
    "model.fit(X_train_2, Y_train, epochs=20)\n",
    "\n",
    "# Test\n",
    "#score = model.evaluate(X_test, Y_test)\n",
    "\n",
    "#print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10047/10047 [00:03<00:00, 2544.81it/s]\n"
     ]
    }
   ],
   "source": [
    "# Rough Testing\n",
    "\n",
    "# Load test dataset. \n",
    "# X_test: board inputs, Y_test: true output.\n",
    "(X_test,Y_test) = load_data('Uncombined Data Files/Yasmin_5_19_10048.txt')\n",
    "\n",
    "# Transform X_test to higher dimension.\n",
    "X_test_2 = gen_features (X_test, X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10047/10047 [00:17<00:00, 558.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ TRUCATION: ------ \n",
      "\n",
      "Avg distance overestimated:  2.732376530181511\n",
      "Avg distance underestimated:  2.1070591299817663\n",
      "E_admiss:  0.23579177864039016\n",
      "E_out:  0.7764506817955609\n",
      "------ ROUNDED: ------ \n",
      "\n",
      "Avg distance overestimated:  2.6403682\n",
      "Avg distance underestimated:  1.8386867\n",
      "E_admiss:  0.3027769483427889\n",
      "E_out:  0.6852791878172588\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dist_over_i = []\n",
    "misclass_i = 0\n",
    "dist_under_i = []\n",
    "\n",
    "dist_over_r = []\n",
    "misclass_r = 0\n",
    "dist_under_r = []\n",
    "\n",
    "for i in tqdm(range(len(X_test))):\n",
    "    nn_heur_i = int(model.predict(X_test_2[i:(i+1),:]))\n",
    "    nn_heur_r = np.around(model.predict(X_test_2[i:(i+1),:]))\n",
    "    man_heur = manhattan(X_test[i].reshape(SIZE,SIZE), model)\n",
    "    y = Y_test[i]\n",
    "    \n",
    "    ### TRUNCATE ###\n",
    "    if (nn_heur_i > y):\n",
    "        dist_over_i.append(nn_heur_i - y)\n",
    "    \n",
    "    if (nn_heur_i <= y):\n",
    "        dist_under_i.append(y - nn_heur_i)\n",
    "    \n",
    "    if (nn_heur_i != y):\n",
    "        misclass_i += 1\n",
    "        \n",
    "    ##### ROUND ##### \n",
    "    if (nn_heur_r > y):\n",
    "        dist_over_r.append(nn_heur_r - y)\n",
    "    \n",
    "    if (nn_heur_r <= y):\n",
    "        dist_under_r.append(y - nn_heur_r)\n",
    "    \n",
    "    if (nn_heur_r != y):\n",
    "        misclass_r += 1\n",
    "    \n",
    "avg_dist_over_i = np.mean(np.asarray(dist_over_i))\n",
    "avg_dist_under_i = np.mean(np.asarray(dist_under_i))\n",
    "out_sample_error_i = misclass_i / len(X_test)\n",
    "\n",
    "avg_dist_over_r = np.mean(np.asarray(dist_over_r))\n",
    "avg_dist_under_r = np.mean(np.asarray(dist_under_r))\n",
    "out_sample_error_r = misclass_r / len(X_test)\n",
    " \n",
    "print(\"------ TRUCATION: ------\")\n",
    "print(\"Avg distance overestimated: \", avg_dist_over_i)\n",
    "print(\"Avg distance underestimated: \", avg_dist_under_i)\n",
    "print(\"E_admiss: \", len(dist_over_i)/len(X_test))\n",
    "print(\"E_out: \", out_sample_error_i)\n",
    "\n",
    "print(\"------ ROUNDED: ------\")\n",
    "print(\"Avg distance overestimated: \", avg_dist_over_r)\n",
    "print(\"Avg distance underestimated: \", avg_dist_under_r)\n",
    "print(\"E_admiss: \", len(dist_over_r)/len(X_test))\n",
    "print(\"E_out: \", out_sample_error_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
