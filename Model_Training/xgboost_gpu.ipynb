{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "xgboost_gpu.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "0SJlVrDIVYIX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow.keras.backend as K\n",
        "import numpy as np\n",
        "import sys\n",
        "import pickle\n",
        "import pandas as pd\n",
        "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
        "import xgboost as xgb\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "from constants import * \n",
        "from heuristic import *\n",
        "from io_help import *\n",
        "from solver import *"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7B3JuNRIOw47",
        "colab_type": "code",
        "outputId": "f02e649a-80cb-40ae-9712-3dbf2092e7cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "from tqdm import tqdm\n",
        "import keras.backend as K\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Dense, Dropout, Conv2D, Flatten, Input\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from keras.models import load_model\n",
        "import keras.losses"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KJXJrTymO-CJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_data(file_name):\n",
        "    \"\"\"\n",
        "    This function reads in training data from a file and returns \n",
        "    the boards in X and their labels in Y as a tuple. \n",
        "    \"\"\"\n",
        "    file = open(file_name, \"r\")\n",
        "    X = []\n",
        "    Y = []\n",
        "    \n",
        "\n",
        "    for string in file: \n",
        "        (board, dist) = string_to_board_and_dist(string)\n",
        "        X_temp = np.concatenate((board.reshape(16)), axis=None)\n",
        "        X.append(X_temp)\n",
        "        Y.append(dist)\n",
        "        \n",
        "    file.close()\n",
        "    X_train = np.asarray(X)\n",
        "    Y_train = np.asarray(Y)\n",
        "    return(X_train, Y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wtu0woE_O_I9",
        "colab_type": "code",
        "outputId": "6a430388-edd2-4d40-bdb2-f392ffd34bc4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Load dataset. \n",
        "# X: board inputs, Y: true output.\n",
        "(X_train,Y_train) = load_data('All_Data.txt')\n",
        "print(X_train.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(395715, 16)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_iq_xIj9PMJ5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Generates additional features.\n",
        "# X: the input data file.\n",
        "# X_train: the original training data file (not transformed).\n",
        "def gen_features (X, X_train, knn_model):\n",
        "    #data_arr = np.zeros([len(X), 16*2*2 + 2])\n",
        "    data_arr = np.zeros([len(X), (16)*2*2 + 2])\n",
        "   # disp_2D = np.zeros([len(X), 32])\n",
        "    man_ham_2D = np.zeros([len(X), 2])\n",
        "    one_hot_2D = np.zeros([len(X), 256+32])\n",
        "    pred = knn_model.kneighbors(X)\n",
        "    \n",
        "    \n",
        "    #for i in tqdm(range(len(X))):\n",
        "    for i in range(len(X)):\n",
        "        row = X[i]\n",
        "        # Grabs the rows in X corresponding to 50 nearest neighbors of X[i].\n",
        "        # pred[1][i] contains a list of the indices of the 50 nearest neighbors.\n",
        "        data = X_train[pred[1][i]]\n",
        "        # Divide X[i] by each of its neighbors. div should be a \n",
        "        # 50 x 16 matrix, i.e. div[j] = X[i] / X[j].\n",
        "        div = (row / data)\n",
        "        # Subtract X[i] by each of its neighbors. diff should be a \n",
        "        # 50 x 16 dimension matrix.\n",
        "        diff = (row - data)\n",
        "        # concat is a 50 x 32 matrix.\n",
        "        concat = np.concatenate([div, diff], axis = 1)\n",
        "        # means is a 50 x 32 matrix.\n",
        "        # std is a 50 x 32 matrix.\n",
        "        means, stds = np.nanmean(concat, axis = 0), np.nanstd(concat, axis = 0)\n",
        "        # Populate data_arr with newly generated features.\n",
        "        data_arr[i, :len(means)] = means\n",
        "        data_arr[i, len(means):len(means) + len(stds)] = stds\n",
        "        data_arr[i, -1] = np.nanmean(pred[0][i])\n",
        "        data_arr[i, -2] = np.nanstd(pred[0][i])\n",
        "        \n",
        "        # Calculate Displacements\n",
        "       # disp_2D[i] = nn.calc_displacements(row.reshape(4,4))\n",
        "        \n",
        "        # Manhattan, Hamming distances\n",
        "        man = manhattan(row.reshape(4,4), None)\n",
        "        ham = hamming(row.reshape(4,4), None)\n",
        "        man_ham_2D[i,0] = man\n",
        "        man_ham_2D[i,1] = ham\n",
        "        one_hot_2D[i] = get_rep_2(row.reshape(4,4))\n",
        "        \n",
        "    # Concatenate generated features to the original dataset.\n",
        "    return np.concatenate([data_arr, one_hot_2D, man_ham_2D], axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "87H2LOd0ehpi",
        "colab_type": "code",
        "outputId": "1d0eb5c0-3472-4b25-e30e-c1486920c1ed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        }
      },
      "source": [
        "knn_model = NearestNeighbors(n_neighbors=151, n_jobs = -1).fit(X_train,Y_train)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-1e5cce8c3141>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mknn_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNearestNeighbors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_neighbors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m151\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mX_train_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mknn_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-5-567d51db260f>\u001b[0m in \u001b[0;36mgen_features\u001b[0;34m(X, X_train, knn_model)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0;31m# Manhattan, Hamming distances\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0mman\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmanhattan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m         \u001b[0mham\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhamming\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0mman_ham_2D\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mman\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'heapq' has no attribute 'manhattan'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0H0I1qAyw25-",
        "colab_type": "code",
        "outputId": "2b5ac755-8e96-422a-a318-cdfc4efbdafd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        }
      },
      "source": [
        "X_train_2 = gen_features(X_train, X_train, knn_model)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-94c1ded7e970>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX_train_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mknn_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-5-567d51db260f>\u001b[0m in \u001b[0;36mgen_features\u001b[0;34m(X, X_train, knn_model)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0;31m# Manhattan, Hamming distances\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0mman\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmanhattan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m         \u001b[0mham\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhamming\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0mman_ham_2D\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mman\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'heapq' has no attribute 'manhattan'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5TQ_h06-Vbi2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def one_hot_encode(board):\n",
        "    \"\"\" \n",
        "    This function one hot encodes the board into a length 256 array.\n",
        "    The one hot encoding gives the location of each number in the board.\n",
        "    For example, the first 16 of the 256 numbers will indicate where on\n",
        "    the board the 1 tile is. \n",
        "    \"\"\"\n",
        "\n",
        "    flat = (board.reshape(SIZE ** 2)).tolist()\n",
        "\n",
        "    X = []\n",
        "    for i in np.arange(1,17): \n",
        "        encoding = np.zeros(SIZE ** 2)\n",
        "        encoding[flat.index(i)] = 1\n",
        "\n",
        "        X.append(encoding)\n",
        "\n",
        "    X = (np.asarray(X).reshape(SIZE ** 4))\n",
        "\n",
        "    # Potentially append Manhattan distance. \n",
        "    # np.append(X, manhattan(board))\n",
        "\n",
        "    return X"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4-urgvrKwj8n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def calc_displacements(board):\n",
        "    \"\"\"given a board, returns SIZE^2 array containing distances of tile in\n",
        "    each entry to proper location\"\"\"\n",
        "    dis_x = np.zeros(SIZE ** 2)\n",
        "    dis_y = np.zeros(SIZE ** 2)\n",
        "\n",
        "    for i in range(SIZE):\n",
        "        for j in range(SIZE):\n",
        "            curr = board[i,j]\n",
        "            (x, y) = get_proper_loc(curr)\n",
        "            dis_x[SIZE * i + j] = x-i\n",
        "            dis_y[SIZE * i + j] = y-j\n",
        "    return np.concatenate((dis_x, dis_y))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8i5zVnnfwoYX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_rep_2(board):\n",
        "    \"\"\"returns representation of one-hot encoded board with additional 16 \n",
        "    entries which encode distnaces entry in eqch square is from proper location\"\"\"\n",
        "    encode = one_hot_encode(board)\n",
        "    displacements = calc_displacements(board)\n",
        "    return np.concatenate((encode, displacements))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NqJe-edPwo-Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_data_2(file_name):\n",
        "    \"\"\"same as load_data except that has additional 16 entries which\n",
        "    encode distnaces entry in eqch square is from proper location\"\"\"\n",
        "    file = open(file_name, \"r\")\n",
        "\n",
        "    X = []\n",
        "    Y = []\n",
        "    for line in file:\n",
        "        (board, dist) = string_to_board_and_dist(line)\n",
        "        Y.append(dist)\n",
        "        X.append(get_rep_2(board))\n",
        "\n",
        "\n",
        "    file.close()\n",
        "    return (np.asarray(X), np.asarray(Y))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "be9z-XE8VdXL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_data(file_name):\n",
        "    \"\"\"\n",
        "    This function reads in training data from a file and returns \n",
        "    the one-hot encoded data X and their labels Y as a tuple. \n",
        "    \"\"\"\n",
        "    file = open(file_name, \"r\")\n",
        "\n",
        "    X = []\n",
        "    Y = []\n",
        "\n",
        "    for string in file: \n",
        "        (board, dist) = string_to_board_and_dist(string) \n",
        "\n",
        "        X.append(one_hot_encode(board))\n",
        "        Y.append(dist)\n",
        "\n",
        "    file.close()\n",
        "\n",
        "    return(np.asarray(X),np.asarray(Y))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PEE759CoVgp1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_data_csv(file_name):\n",
        "    return pd.read_csv(file_name, index_col=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-y13luYeViGx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def shift_mse_2(y_true, y_pred):\n",
        "    loss = (1 + 100/ (1 + K.exp(-(y_pred - y_true)))) * K.square(y_pred - y_true)\n",
        "    loss = K.mean(loss, axis = 1)\n",
        "    return loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IGMWpJmXmNrY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def exp_loss_2(y_true, y_pred):\n",
        "    \"\"\"\n",
        "    Custom loss function. \n",
        "    \"\"\"\n",
        "    loss = K.exp((y_pred - y_true)) / 2\n",
        "    loss = loss + K.square(y_pred - y_true)\n",
        "    loss = K.mean(loss, axis = 1)\n",
        "\n",
        "    return loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zj_JM59QVitj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(X_train, Y_train):\n",
        "    \n",
        "    #train_data = load_data(\"Yasmin_40360_50knn_Trans.csv\")\n",
        "\n",
        "    #X_train = train_data[train_data.columns[:-1]].values\n",
        "    #Y_train = train_data[train_data.columns[-1]].values\n",
        "    \n",
        "    model = XGBClassifier(verbose_eval=True, tree_method='gpu_hist', \n",
        "                          learning_rate=0.3, max_depth=6, min_child_weight=4, \n",
        "                          n_estimators=200, objective='mse_shift_2', \n",
        "                          subsample=0.8, colsample_bytree=0.8,\n",
        "                          verbosity=2, gamma=0.1)\n",
        "\n",
        "    model.fit(X_train, Y_train)\n",
        "    \n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tnUE_wcUVke-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = train()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qXUBVWg_XMzp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pickle.dump(model, open(\"xg_model_penalize_fe_200_6_4\", \"wb\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xdCPBEfte3PV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def find_over_estimate(file_name, model):\n",
        "    \"\"\"\n",
        "    This function takes in a model saved in model_file and data points in \n",
        "    file_name and prints out the percentage of times said model predicted \n",
        "    a distance greater than the actual distance and the percentage of times\n",
        "    said model predicted a distance less than the Manhattan Distance\n",
        "    \"\"\"\n",
        "    data = open(file_name, \"r\")\n",
        "    over = []\n",
        "    under = []\n",
        "\n",
        "    count = 1\n",
        "    for line in data:\n",
        "        (board, dist) = string_to_board_and_dist(line)\n",
        "        man_dist = manhattan(board, None)\n",
        "        pred = xgboost_heuristic_2(board, model)\n",
        "        over.append(pred > dist)\n",
        "        under.append(pred < man_dist)\n",
        "        \n",
        "        if (count % 1000 == 1):\n",
        "            print(count)\n",
        "        count += 1\n",
        "\n",
        "    print(\"prediction less than manhattan percent of the time\", sum(under) * 100 / len(under))\n",
        "    print(\"prediction greater than actual distance precent of the time\", sum(over) * 100 / len(over))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lLP0CvsDe4Nl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "find_over_estimate(\"Test_Data.txt\", model)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ab88QqfrfDpn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def xgboost_heuristic_2(board, model):\n",
        "\n",
        "    \"\"\"\n",
        "    This function takes in a board and a trained NN model and returns\n",
        "    the heuristic the model predicts.\n",
        "    \"\"\"\n",
        "\n",
        "    return model.predict(get_rep_2(board).reshape(1,288))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}