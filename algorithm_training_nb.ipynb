{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Conv2D, Flatten, Input\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from tensorflow.keras.models import load_model\n",
    "import tensorflow.keras.losses\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "from constants import * \n",
    "from heuristic import *\n",
    "from io_help import *\n",
    "from solver import *\n",
    "\n",
    "def one_hot_encode(board):\n",
    "    \"\"\" \n",
    "    This function one hot encodes the board into a length 256 array.\n",
    "    The one hot encoding gives the location of each number in the board.\n",
    "    For example, the first 16 of the 256 numbers will indicate where on\n",
    "    the board the 1 tile is. \n",
    "    \"\"\"\n",
    "\n",
    "    flat = (board.reshape(SIZE ** 2)).tolist()\n",
    "\n",
    "    X = []\n",
    "    for i in np.arange(1,17): \n",
    "        encoding = np.zeros(SIZE ** 2)\n",
    "        encoding[flat.index(i)] = 1\n",
    "\n",
    "        X.append(encoding)  \n",
    "\n",
    "    X = (np.asarray(X).reshape(SIZE ** 4))\n",
    "\n",
    "    # Potentially append Manhattan distance. \n",
    "    # np.append(X, manhattan(board))\n",
    "\n",
    "    return X\n",
    "\n",
    "def load_data(file_name):\n",
    "    \"\"\"\n",
    "    This function reads in training data from a file and returns \n",
    "    the one-hot encoded data X and their labels Y as a tuple. \n",
    "    \"\"\"\n",
    "    file = open(file_name, \"r\")\n",
    "\n",
    "    X = []\n",
    "    Y = []\n",
    "\n",
    "    for string in file: \n",
    "        (board, classification) = string_to_board_and_dist(string) \n",
    "\n",
    "        X.append(one_hot_encode(board))\n",
    "        Y.append(classification)\n",
    "\n",
    "    file.close()\n",
    "\n",
    "    return(np.asarray(X),np.asarray(Y))\n",
    "\n",
    "def evaluate(X,Y):\n",
    "    \"\"\"\n",
    "    This function reads in training data from a file and \n",
    "    trains and evaluates NN model using kfold validation. \n",
    "    \"\"\"\n",
    "    #(X,Y) = load_data(file_name)\n",
    "\n",
    "    #Y = to_categorical(Y)\n",
    "\n",
    "    # Implement K-fold cross validation\n",
    "    kfold = KFold(n_splits=10, shuffle=True, random_state=2020)\n",
    "\n",
    "    for train, test in kfold.split(X, Y):\n",
    "        # Build Model\n",
    "        model = Sequential()\n",
    "\n",
    "        # Input Layer\n",
    "        i = Input(shape = (256,))\n",
    "        x_1 = Dense(256, activation='relu')(i)\n",
    "        #x_2 = Dropout(0.2)(x_1)\n",
    "        o = Dense(5, activation='softmax')(x_1)\n",
    "        model = Model(i,o)\n",
    "\n",
    "        # Define the optimizer and loss function\n",
    "        model.compile(optimizer='adam', loss=\"sparse_categorical_crossentropy\", metrics=['accuracy'])\n",
    "\n",
    "        # Train \n",
    "        model.fit(X, Y, epochs=15, verbose=1)\n",
    "\n",
    "        # Evaluate\n",
    "        score = model.evaluate(X[test], Y[test], verbose=0)\n",
    "        print(score)\n",
    "\n",
    "    return model\n",
    "\n",
    "def train(X,Y):\n",
    "    \"\"\"\n",
    "    This function reads in training data from a file and returns a \n",
    "    trained NN model. \n",
    "    \"\"\"\n",
    "    #(X,Y) = load_data(file_name)\n",
    "\n",
    "    #Y = to_categorical(Y)\n",
    "\n",
    "    # Build Model\n",
    "    model = Sequential()\n",
    "\n",
    "    # Input Layer\n",
    "    i = Input(shape = (256,))\n",
    "    x_1 = Dense(256, activation='relu')(i)\n",
    "    #x_2 = Dropout(0.2)(x_1)\n",
    "    o = Dense(5, activation='softmax')(x_1)\n",
    "    model = Model(i,o)\n",
    "\n",
    "    # Define the optimizer and loss function\n",
    "    model.compile(optimizer='adam', loss=\"sparse_categorical_crossentropy\", metrics=['accuracy'])\n",
    "\n",
    "    # Train \n",
    "    model.fit(X, Y, epochs=50, verbose=1)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X,Y) = load_data(\"final_portfolio_data.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 395715 samples\n",
      "Epoch 1/50\n",
      "395715/395715 [==============================] - 19s 47us/sample - loss: 0.6937 - accuracy: 0.6926 - loss: 0.6938 - accuracy: 0.69\n",
      "Epoch 2/50\n",
      "395715/395715 [==============================] - 19s 47us/sample - loss: 0.6419 - accuracy: 0.7138 - loss: 0.6420 - \n",
      "Epoch 3/50\n",
      "395715/395715 [==============================] - 19s 47us/sample - loss: 0.6176 - accuracy: 0.7263\n",
      "Epoch 4/50\n",
      "395715/395715 [==============================] - 19s 48us/sample - loss: 0.5998 - accuracy: 0.7365\n",
      "Epoch 5/50\n",
      "395715/395715 [==============================] - 21s 53us/sample - loss: 0.5856 - accuracy: 0.7439\n",
      "Epoch 6/50\n",
      "395715/395715 [==============================] - 20s 50us/sample - loss: 0.5747 - accuracy: 0.7500\n",
      "Epoch 7/50\n",
      "395715/395715 [==============================] - 23s 58us/sample - loss: 0.5653 - accuracy: 0.7546\n",
      "Epoch 8/50\n",
      "395715/395715 [==============================] - 17s 43us/sample - loss: 0.5576 - accuracy: 0.7586 - loss: 0\n",
      "Epoch 9/50\n",
      "395715/395715 [==============================] - 17s 42us/sample - loss: 0.5513 - accuracy: 0.7623\n",
      "Epoch 10/50\n",
      "395715/395715 [==============================] - 22s 55us/sample - loss: 0.5454 - accuracy: 0.7651\n",
      "Epoch 11/50\n",
      "395715/395715 [==============================] - 24s 60us/sample - loss: 0.5401 - accuracy: 0.7683\n",
      "Epoch 12/50\n",
      "395715/395715 [==============================] - 21s 52us/sample - loss: 0.5352 - accuracy: 0.770619s - loss: 0.5168 - accuracy: 0.7 - ETA: 19s - loss: 0.5175 - accuracy  - ETA: 17s - loss: 0.5210 - accuracy: 0.77 - ETA: 16s - l - ETA:  - ETA: 0s - loss: 0.5349 - accu\n",
      "Epoch 13/50\n",
      "395715/395715 [==============================] - 20s 50us/sample - loss: 0.5318 - accuracy: 0.773117s - ETA: 8s - loss: 0.5239 - ac - ETA - ETA: 1s - loss: 0.5307 - accuracy: 0.77 - ETA: 1s - loss: 0.5308 - accu\n",
      "Epoch 14/50\n",
      "395715/395715 [==============================] - 20s 50us/sample - loss: 0.5280 - accuracy: 0.774917s - loss: 0.5126 - ETA: 17s - loss: 0.5126 - ac - E - ETA: 13s - loss: 0. - ETA: 12s - loss: 0.5164 - accuracy: 0.779 - ETA: \n",
      "Epoch 15/50\n",
      "395715/395715 [==============================] - 20s 50us/sample - loss: 0.5245 - accuracy: 0.776716s - loss: 0.5059 - ETA:  - ETA: 11s - loss: 0.5133 - ac - ETA: 7s - ETA: 1s - loss: 0.5241 - accuracy: 0. - ETA: 1s - loss: 0.5243 - accuracy: 0.77 - ETA: 1s - loss: 0.5242 - accuracy: 0.77 - ETA:  - ETA: 0s - loss: 0.5247 - accuracy - ETA: 0s - loss: 0.5245 - accuracy\n",
      "Epoch 16/50\n",
      "395715/395715 [==============================] - 20s 50us/sample - loss: 0.5216 - accuracy: 0.7779\n",
      "Epoch 17/50\n",
      "395715/395715 [==============================] - 19s 48us/sample - loss: 0.5188 - accuracy: 0.7800\n",
      "Epoch 18/50\n",
      "395715/395715 [==============================] - 19s 47us/sample - loss: 0.5163 - accuracy: 0.7804 - ETA: 16s - loss: 0.4982 - accuracy:  - ETA: 16s - loss: 0.4981 - accu - ETA: 15s - loss: 0.4988 - accuracy: 0 - ETA: 15s - loss: 0.4995 - ETA: 14s - loss: 0.5004 - accuracy: 0 - ETA: 14s - loss: - ETA: - ETA: 11s - loss: 0.5056 - accuracy: 0.785 - ETA: 11s - loss:  - ETA - ETA: 6s - l - ETA: 5s - - ETA: 1s - loss: 0.5146 - accu - ETA: 1s - loss: 0.5150 - accuracy - E\n",
      "Epoch 19/50\n",
      "395715/395715 [==============================] - 19s 47us/sample - loss: 0.5140 - accuracy: 0.782317s - loss: 0.4 - ETA: 16s - loss: 0.4986 - a - ETA: 15s - loss: 0.4999  - ETA: 14s - loss: 0.5020 - accuracy: 0. - ETA: 14s - loss: 0.5028 - acc - ETA: 13s - loss: 0.5028 - accuracy: - ETA: 13s - loss: 0.5034 - accura - ETA: 12s - loss: 0.5038 - ac - ETA: 11s - loss: 0.5055 - accuracy: 0.785 - ETA: 11s - loss: 0.5054 - accuracy: 0. - ETA: 7s - loss: 0.5088 - accuracy: 0. - ETA: 7s - loss: 0 - - ETA: 4s - loss: 0.5104 -  - ETA: 4s\n",
      "Epoch 20/50\n",
      "395715/395715 [==============================] - 18s 46us/sample - loss: 0.5117 - accuracy: 0.783315s - loss: 0.4904 - accuracy: - ETA: 8s - loss: 0.5053 - ac - ETA: 7s - loss: 0.5 - ETA: 7s - loss: 0.5064 - accu - ETA: 3s - loss: 0.5098 - accuracy:  - ETA: 3s - loss: 0.5100 - accu - ETA: 1s - loss: 0.5111 - accuracy: 0. - ETA: 1s - loss: 0.511 - ETA: 0s - loss: 0.5117 - accuracy: 0.78\n",
      "Epoch 21/50\n",
      "395715/395715 [==============================] - 18s 45us/sample - loss: 0.5096 - accuracy: 0.784316s - loss: 0.4886 - accuracy:  - ETA: 16s - loss: 0.490 - ETA: 15s - loss: 0.4919 - accuracy: 0.792 - ETA: 15s - loss: 0.49 - ETA: 14s - loss: 0.4 - ETA: 13s - loss: 0.4955 - accur\n",
      "Epoch 22/50\n",
      "395715/395715 [==============================] - 18s 45us/sample - loss: 0.5076 - accuracy: 0.785217s - loss: 0 - ETA: 14s - loss: 0.495 - ETA: 13s  - ETA: 2s - loss: 0.5052 - accuracy:  - ETA: 2s - loss: 0.5056 - accuracy: 0. - ETA:  - ETA: 1s - loss: 0.5065 - accu - ETA: 0s - loss: 0.5075 - accuracy: 0.78 - ETA: 0s - loss: 0.5074 - accuracy: 0. - ETA: 0s - loss: 0.5075 - accuracy: 0.\n",
      "Epoch 23/50\n",
      "395715/395715 [==============================] - 19s 47us/sample - loss: 0.5058 - accuracy: 0.786418s - loss: 0.4960 - accuracy: 0. - ETA: 1 - ETA: 15s - loss: 0.4868 - accuracy: 0. - ETA: 15s - loss: 0.4893 - accuracy: 0.7 - ETA: 15s - los - ETA: 6s - loss: 0.5005 - accura - ETA: \n",
      "Epoch 24/50\n",
      "395715/395715 [==============================] - 20s 50us/sample - loss: 0.5042 - accuracy: 0.787119s - loss: 0.4883 - ETA: 17s - loss: 0 - ETA: 15s - loss: 0.4916 -  - ETA: 14s - loss: 0.4921 - accuracy:  - ETA: 13s - loss: 0.4930 - accur - ETA: 13s - loss: 0.4938 - accuracy: - ETA: 12s - loss: 0.4948 - accu - ETA: 11 - ETA: 3s - loss: 0.5010 - accu - ETA: 3s - loss: 0.5011 - accu - ETA: 3s - loss: 0.5014  - ETA: 1s - loss: 0.5034 - accura\n",
      "Epoch 25/50\n",
      "395715/395715 [==============================] - 18s 45us/sample - loss: 0.5027 - accuracy: 0.788016s  - ETA: 14s - loss: 0.4895 - accuracy - ETA: 14s - loss - ETA: 0s - loss: 0.5028 - accuracy: 0.78\n",
      "Epoch 26/50\n",
      "395715/395715 [==============================] - 18s 45us/sample - loss: 0.5011 - accuracy: 0.7892 - loss:\n",
      "Epoch 27/50\n",
      "395715/395715 [==============================] - 18s 45us/sample - loss: 0.4997 - accuracy: 0.789515s - loss: 0.4851 - - ETA: 14s - loss: 0.4863 - accuracy: 0.\n",
      "Epoch 28/50\n",
      "395715/395715 [==============================] - 18s 44us/sample - loss: 0.4983 - accuracy: 0.790716s - ETA: 15s - loss: 0.4758 -  - ETA: 14s - loss: 0.4785 - accuracy: 0.8 - ETA: - ETA: 1s - loss: 0.4965 - accura - ETA: 1s - loss: 0.4967 - accuracy: 0.79 - ETA: 1s - loss: 0.496\n",
      "Epoch 29/50\n",
      "395715/395715 [==============================] - 17s 44us/sample - loss: 0.4968 - accuracy: 0.791517s - loss: 0. - ETA: 16s - loss: - ETA: 0s - los\n",
      "Epoch 30/50\n",
      "395715/395715 [==============================] - 18s 45us/sample - loss: 0.4958 - accuracy: 0.7916 - loss: 0.4958 - accura\n",
      "Epoch 31/50\n",
      "395715/395715 [==============================] - 17s 44us/sample - loss: 0.4944 - accuracy: 0.7928\n",
      "Epoch 32/50\n",
      "395715/395715 [==============================] - 17s 44us/sample - loss: 0.4930 - accuracy: 0.793317s - los - ETA: 15s - ETA: 0s - loss: 0.4923 - accu - ETA: 0s - loss: 0.4926 - ac\n",
      "Epoch 33/50\n",
      "395715/395715 [==============================] - 18s 44us/sample - loss: 0.4923 - accuracy: 0.7934\n",
      "Epoch 34/50\n",
      "395715/395715 [==============================] - 17s 44us/sample - loss: 0.4910 - accuracy: 0.7944\n",
      "Epoch 35/50\n",
      "395715/395715 [==============================] - 17s 44us/sample - loss: 0.4902 - accuracy: 0.7945\n",
      "Epoch 36/50\n",
      "395715/395715 [==============================] - 17s 44us/sample - loss: 0.4892 - accuracy: 0.7949 - loss:\n",
      "Epoch 37/50\n",
      "395715/395715 [==============================] - 17s 44us/sample - loss: 0.4882 - accuracy: 0.7956\n",
      "Epoch 38/50\n",
      "395715/395715 [==============================] - 19s 48us/sample - loss: 0.4874 - accuracy: 0.7959 - loss: 0.487\n",
      "Epoch 39/50\n",
      "395715/395715 [==============================] - 18s 45us/sample - loss: 0.4867 - accuracy: 0.7966 ETA: 1s - loss: 0.4864 - accuracy: 0.79 - ETA: 1s - loss: 0.4865 - accu - ETA: \n",
      "Epoch 40/50\n",
      "395715/395715 [==============================] - 18s 44us/sample - loss: 0.4860 - accuracy: 0.7969\n",
      "Epoch 41/50\n",
      "395715/395715 [==============================] - 17s 44us/sample - loss: 0.4850 - accuracy: 0.7979\n",
      "Epoch 42/50\n",
      "395715/395715 [==============================] - 17s 44us/sample - loss: 0.4840 - accuracy: 0.7977\n",
      "Epoch 43/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "395715/395715 [==============================] - 17s 44us/sample - loss: 0.4830 - accuracy: 0.7978\n",
      "Epoch 44/50\n",
      "395715/395715 [==============================] - 17s 44us/sample - loss: 0.4824 - accuracy: 0.7983\n",
      "Epoch 45/50\n",
      "395715/395715 [==============================] - 18s 45us/sample - loss: 0.4817 - accuracy: 0.7985\n",
      "Epoch 46/50\n",
      "395715/395715 [==============================] - 19s 47us/sample - loss: 0.4810 - accuracy: 0.7993 - loss: 0.4805 - accuracy: 0.79 - ETA: 0s -\n",
      "Epoch 47/50\n",
      "395715/395715 [==============================] - 20s 50us/sample - loss: 0.4804 - accuracy: 0.7997\n",
      "Epoch 48/50\n",
      "395715/395715 [==============================] - 18s 46us/sample - loss: 0.4798 - accuracy: 0.8001\n",
      "Epoch 49/50\n",
      "395715/395715 [==============================] - 17s 44us/sample - loss: 0.4794 - accuracy: 0.8000\n",
      "Epoch 50/50\n",
      "395715/395715 [==============================] - 17s 44us/sample - loss: 0.4787 - accuracy: 0.8010 - loss: 0.4786 - accuracy: \n",
      "[[ 2  3  7  4]\n",
      " [ 9  5  8 16]\n",
      " [ 6  1 14 11]\n",
      " [13 15 10 12]]\n",
      "[[7.46063769e-01 1.16838664e-01 1.37020111e-01 2.67665428e-22\n",
      "  7.74552609e-05]]\n"
     ]
    }
   ],
   "source": [
    "model = train(X,Y)\n",
    "\n",
    "board = gen_board()\n",
    "print(board)\n",
    "print(model.predict(one_hot_encode(board).reshape(1,256)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"algorithm_model_50_no_do.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_6 (InputLayer)         [(None, 256)]             0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 5)                 1285      \n",
      "=================================================================\n",
      "Total params: 67,077\n",
      "Trainable params: 67,077\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2 = load_model(\"algorithm_model_50_no_do.h5\")\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1  3  6  4]\n",
      " [ 9 16  5  7]\n",
      " [15 14 10  8]\n",
      " [11 13  2 12]]\n",
      "[6.2154625e-02 1.5069728e-01 7.8709257e-01 3.2622894e-19 5.5535209e-05]\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "board = gen_board()\n",
    "print(board)\n",
    "print(np.asarray(model.predict(one_hot_encode(board).reshape(1,256)).flatten()))\n",
    "print(np.asarray(model.predict(one_hot_encode(board).reshape(1,256)).flatten()).argmax())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
