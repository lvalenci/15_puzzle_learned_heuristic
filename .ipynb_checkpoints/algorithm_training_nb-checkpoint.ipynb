{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "WARNING:root:Limited tf.compat.v2.summary API due to missing TensorBoard installation.\n",
      "WARNING:root:Limited tf.compat.v2.summary API due to missing TensorBoard installation.\n",
      "WARNING:root:Limited tf.summary API due to missing TensorBoard installation.\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Conv2D, Flatten, Input\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from tensorflow.keras.models import load_model\n",
    "import tensorflow.keras.losses\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "from constants import * \n",
    "from heuristic import *\n",
    "from io_help import *\n",
    "from solver import *\n",
    "\n",
    "def one_hot_encode(board):\n",
    "    \"\"\" \n",
    "    This function one hot encodes the board into a length 256 array.\n",
    "    The one hot encoding gives the location of each number in the board.\n",
    "    For example, the first 16 of the 256 numbers will indicate where on\n",
    "    the board the 1 tile is. \n",
    "    \"\"\"\n",
    "\n",
    "    flat = (board.reshape(SIZE ** 2)).tolist()\n",
    "\n",
    "    X = []\n",
    "    for i in np.arange(1,17): \n",
    "        encoding = np.zeros(SIZE ** 2)\n",
    "        encoding[flat.index(i)] = 1\n",
    "\n",
    "        X.append(encoding)  \n",
    "\n",
    "    X = (np.asarray(X).reshape(SIZE ** 4))\n",
    "\n",
    "    # Potentially append Manhattan distance. \n",
    "    # np.append(X, manhattan(board))\n",
    "\n",
    "    return X\n",
    "\n",
    "def load_data(file_name):\n",
    "    \"\"\"\n",
    "    This function reads in training data from a file and returns \n",
    "    the one-hot encoded data X and their labels Y as a tuple. \n",
    "    \"\"\"\n",
    "    file = open(file_name, \"r\")\n",
    "\n",
    "    X = []\n",
    "    Y = []\n",
    "\n",
    "    for string in file: \n",
    "        (board, classification) = string_to_board_and_dist(string) \n",
    "\n",
    "        X.append(one_hot_encode(board))\n",
    "        Y.append(classification)\n",
    "\n",
    "    file.close()\n",
    "\n",
    "    return(np.asarray(X),np.asarray(Y))\n",
    "\n",
    "def evaluate(X,Y):\n",
    "    \"\"\"\n",
    "    This function reads in training data from a file and \n",
    "    trains and evaluates NN model using kfold validation. \n",
    "    \"\"\"\n",
    "    #(X,Y) = load_data(file_name)\n",
    "\n",
    "    #Y = to_categorical(Y)\n",
    "\n",
    "    # Implement K-fold cross validation\n",
    "    kfold = KFold(n_splits=10, shuffle=True, random_state=2020)\n",
    "\n",
    "    for train, test in kfold.split(X, Y):\n",
    "        # Build Model\n",
    "        model = Sequential()\n",
    "\n",
    "        # Input Layer\n",
    "        i = Input(shape = (256,))\n",
    "        x_1 = Dense(256, activation='relu')(i)\n",
    "        #x_2 = Dropout(0.2)(x_1)\n",
    "        o = Dense(5, activation='softmax')(x_1)\n",
    "        model = Model(i,o)\n",
    "\n",
    "        # Define the optimizer and loss function\n",
    "        model.compile(optimizer='adam', loss=\"sparse_categorical_crossentropy\", metrics=['accuracy'])\n",
    "\n",
    "        # Train \n",
    "        model.fit(X, Y, epochs=15, verbose=1)\n",
    "\n",
    "        # Evaluate\n",
    "        score = model.evaluate(X[test], Y[test], verbose=0)\n",
    "        print(score)\n",
    "\n",
    "    return model\n",
    "\n",
    "def train(X,Y):\n",
    "    \"\"\"\n",
    "    This function reads in training data from a file and returns a \n",
    "    trained NN model. \n",
    "    \"\"\"\n",
    "    #(X,Y) = load_data(file_name)\n",
    "\n",
    "    #Y = to_categorical(Y)\n",
    "\n",
    "    # Build Model\n",
    "    model = Sequential()\n",
    "\n",
    "    # Input Layer\n",
    "    i = Input(shape = (256,))\n",
    "    x_1 = Dense(256, activation='relu')(i)\n",
    "    x_2 = Dropout(0.1)(x_1)\n",
    "    x_3 = Dense(128, activation='relu')(x_2)\n",
    "    x_4 = Dropout(0.1)(x_3)\n",
    "    o = Dense(5, activation='softmax')(x_4)\n",
    "    model = Model(i,o)\n",
    "\n",
    "    # Define the optimizer and loss function\n",
    "    model.compile(optimizer='adam', loss=\"sparse_categorical_crossentropy\", metrics=['accuracy'])\n",
    "\n",
    "    # Train \n",
    "    model.fit(X, Y, epochs=50, verbose=1)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X,Y) = load_data(\"final_portfolio_data2.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 395715 samples\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Limited tf.compat.v2.summary API due to missing TensorBoard installation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "395715/395715 [==============================] - 20s 50us/sample - loss: 0.7004 - accuracy: 0.7052TA: 0s - loss: 0\n",
      "Epoch 2/50\n",
      "395715/395715 [==============================] - 19s 47us/sample - loss: 0.6458 - accuracy: 0.727416s - loss: 0.6603 - accuracy: 0 - ETA: 16s - loss: 0.6556 - - ETA: 15s - loss: 0.6547 - accuracy:  - ETA: 15s - loss: 0.6547 - ETA: 0s - loss: 0.6458 - accuracy\n",
      "Epoch 3/50\n",
      "395715/395715 [==============================] - 21s 53us/sample - loss: 0.6208 - accuracy: 0.7398\n",
      "Epoch 4/50\n",
      "395715/395715 [==============================] - 18s 45us/sample - loss: 0.6025 - accuracy: 0.7480\n",
      "Epoch 5/50\n",
      "395715/395715 [==============================] - 18s 45us/sample - loss: 0.5887 - accuracy: 0.7551\n",
      "Epoch 6/50\n",
      "395715/395715 [==============================] - 17s 44us/sample - loss: 0.5779 - accuracy: 0.7607 - loss: 0.576 - ETA: 1s - loss: 0.577 - ETA: 0s -\n",
      "Epoch 7/50\n",
      "395715/395715 [==============================] - 17s 42us/sample - loss: 0.5683 - accuracy: 0.7653 - - ETA: 4s - - ETA - ETA: 2s - ETA: 1s - loss: 0.5674 - accura - ETA: \n",
      "Epoch 8/50\n",
      "395715/395715 [==============================] - 17s 43us/sample - loss: 0.5609 - accuracy: 0.7685\n",
      "Epoch 9/50\n",
      "395715/395715 [==============================] - 18s 46us/sample - loss: 0.5540 - accuracy: 0.7719\n",
      "Epoch 10/50\n",
      "395715/395715 [==============================] - 18s 44us/sample - loss: 0.5481 - accuracy: 0.7747 - l\n",
      "Epoch 11/50\n",
      "395715/395715 [==============================] - 17s 44us/sample - loss: 0.5431 - accuracy: 0.7766\n",
      "Epoch 12/50\n",
      "395715/395715 [==============================] - 17s 44us/sample - loss: 0.5385 - accuracy: 0.7788 - loss: 0.5386 - \n",
      "Epoch 13/50\n",
      "395715/395715 [==============================] - 17s 43us/sample - loss: 0.5346 - accuracy: 0.7808 10s - loss: 0.5227 - accurac - ETA: 10s -  - ETA: 1s - loss: 0 - ETA: 0s - loss: 0.534\n",
      "Epoch 14/50\n",
      "395715/395715 [==============================] - 17s 42us/sample - loss: 0.5313 - accuracy: 0.7821\n",
      "Epoch 15/50\n",
      "395715/395715 [==============================] - 17s 43us/sample - loss: 0.5281 - accuracy: 0.7844\n",
      "Epoch 16/50\n",
      "395715/395715 [==============================] - 17s 43us/sample - loss: 0.5251 - accuracy: 0.7851\n",
      "Epoch 17/50\n",
      "395715/395715 [==============================] - 20s 51us/sample - loss: 0.5222 - accuracy: 0.78685s - l - ETA:  - ETA: 0s - loss: 0.5221 - accura\n",
      "Epoch 18/50\n",
      "395715/395715 [==============================] - 19s 49us/sample - loss: 0.5199 - accuracy: 0.7883\n",
      "Epoch 19/50\n",
      "395715/395715 [==============================] - 18s 45us/sample - loss: 0.5177 - accuracy: 0.7888\n",
      "Epoch 20/50\n",
      "395715/395715 [==============================] - 18s 45us/sample - loss: 0.5154 - accuracy: 0.7904\n",
      "Epoch 21/50\n",
      "395715/395715 [==============================] - 17s 44us/sample - loss: 0.5132 - accuracy: 0.7910\n",
      "Epoch 22/50\n",
      "395715/395715 [==============================] - 18s 47us/sample - loss: 0.5117 - accuracy: 0.7920\n",
      "Epoch 23/50\n",
      "395715/395715 [==============================] - 18s 46us/sample - loss: 0.5095 - accuracy: 0.7930 - loss: 0.5 - ETA: 4s - loss: 0.506 -\n",
      "Epoch 24/50\n",
      "395715/395715 [==============================] - 17s 43us/sample - loss: 0.5080 - accuracy: 0.7936 - l - ETA: 0s - loss: 0.5079 - accuracy: 0.79\n",
      "Epoch 25/50\n",
      "395715/395715 [==============================] - 16s 40us/sample - loss: 0.5066 - accuracy: 0.7941\n",
      "Epoch 26/50\n",
      "395715/395715 [==============================] - 16s 39us/sample - loss: 0.5052 - accuracy: 0.7951\n",
      "Epoch 27/50\n",
      "395715/395715 [==============================] - 15s 39us/sample - loss: 0.5036 - accuracy: 0.7958 - loss: 0.5026 \n",
      "Epoch 28/50\n",
      "395715/395715 [==============================] - 15s 39us/sample - loss: 0.5026 - accuracy: 0.7959 - loss: 0 - ETA: 0s - loss: 0.501 - ETA: 0s - loss: 0.5025 - accuracy: 0.\n",
      "Epoch 29/50\n",
      "395715/395715 [==============================] - 15s 39us/sample - loss: 0.5010 - accuracy: 0.7973\n",
      "Epoch 30/50\n",
      "395715/395715 [==============================] - 15s 39us/sample - loss: 0.5001 - accuracy: 0.7970\n",
      "Epoch 31/50\n",
      "395715/395715 [==============================] - 16s 39us/sample - loss: 0.4983 - accuracy: 0.7977\n",
      "Epoch 32/50\n",
      "395715/395715 [==============================] - 15s 39us/sample - loss: 0.4977 - accuracy: 0.7980\n",
      "Epoch 33/50\n",
      "395715/395715 [==============================] - 15s 39us/sample - loss: 0.4966 - accuracy: 0.7993\n",
      "Epoch 34/50\n",
      "395715/395715 [==============================] - 15s 39us/sample - loss: 0.4954 - accuracy: 0.7998\n",
      "Epoch 35/50\n",
      "395715/395715 [==============================] - 16s 41us/sample - loss: 0.4944 - accuracy: 0.8004\n",
      "Epoch 36/50\n",
      "395715/395715 [==============================] - 17s 44us/sample - loss: 0.4935 - accuracy: 0.800315s - loss: 0.475 - ETA:  - ETA: 5s - l - ETA - ETA: 2s - loss: 0.4917  - ETA: 0s - loss: 0.4934 - accu\n",
      "Epoch 37/50\n",
      "395715/395715 [==============================] - 18s 46us/sample - loss: 0.4927 - accuracy: 0.8012\n",
      "Epoch 38/50\n",
      "395715/395715 [==============================] - 17s 43us/sample - loss: 0.4918 - accuracy: 0.8012\n",
      "Epoch 39/50\n",
      "395715/395715 [==============================] - 19s 47us/sample - loss: 0.4909 - accuracy: 0.8017 - loss: 0.4894 - accuracy: 0. - ETA: 2s - l - ETA: 1s - loss: 0.4896 - ac\n",
      "Epoch 40/50\n",
      "395715/395715 [==============================] - 18s 47us/sample - loss: 0.4901 - accuracy: 0.8022\n",
      "Epoch 41/50\n",
      "395715/395715 [==============================] - 19s 49us/sample - loss: 0.4893 - accuracy: 0.8024\n",
      "Epoch 42/50\n",
      "395715/395715 [==============================] - 19s 49us/sample - loss: 0.4886 - accuracy: 0.8025\n",
      "Epoch 43/50\n",
      "395715/395715 [==============================] - 19s 49us/sample - loss: 0.4880 - accuracy: 0.8033\n",
      "Epoch 44/50\n",
      "395715/395715 [==============================] - 20s 51us/sample - loss: 0.4870 - accuracy: 0.8031\n",
      "Epoch 45/50\n",
      "395715/395715 [==============================] - 19s 49us/sample - loss: 0.4864 - accuracy: 0.8039 - loss: 0.4857 - accuracy: 0.80 - ETA: 0s - loss: 0.4858 - accuracy:  - ETA: 0s - loss: 0\n",
      "Epoch 46/50\n",
      "395715/395715 [==============================] - 19s 47us/sample - loss: 0.4857 - accuracy: 0.8048\n",
      "Epoch 47/50\n",
      "395715/395715 [==============================] - 17s 44us/sample - loss: 0.4849 - accuracy: 0.804513s - loss: 0.4648 - accuracy: 0.8 -  - ETA: 6s - loss: 0.4\n",
      "Epoch 48/50\n",
      "395715/395715 [==============================] - 18s 45us/sample - loss: 0.4844 - accuracy: 0.8046 - loss: 0.4\n",
      "Epoch 49/50\n",
      "395715/395715 [==============================] - 17s 44us/sample - loss: 0.4840 - accuracy: 0.8047\n",
      "Epoch 50/50\n",
      "395715/395715 [==============================] - 17s 43us/sample - loss: 0.4833 - accuracy: 0.8052\n",
      "[[ 5  1  7  4]\n",
      " [ 3  2 11  8]\n",
      " [ 9 10  6 12]\n",
      " [13 16 14 15]]\n",
      "[[4.1237762e-03 9.7841704e-01 1.9778830e-03 1.5481270e-02 2.7713702e-14]]\n"
     ]
    }
   ],
   "source": [
    "model = train(X,Y)\n",
    "\n",
    "board = gen_board()\n",
    "print(board)\n",
    "print(model.predict(one_hot_encode(board).reshape(1,256)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"./Algorithm_Models/algorithm_model_50_new.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 256)]             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 5)                 1285      \n",
      "=================================================================\n",
      "Total params: 67,077\n",
      "Trainable params: 67,077\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2 = load_model(\"./Algorithm_Models/algorithm_model_50_new.h5\")\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[16  1  2 12]\n",
      " [ 5 10  6  4]\n",
      " [ 9  8  3  7]\n",
      " [13 14 11 15]]\n",
      "[0.26458484 0.64832425 0.05417242 0.03118835 0.00173012]\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "board = gen_board()\n",
    "print(board)\n",
    "print(np.asarray(model2.predict(one_hot_encode(board).reshape(1,256)).flatten()))\n",
    "print(np.asarray(model2.predict(one_hot_encode(board).reshape(1,256)).flatten()).argmax())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
