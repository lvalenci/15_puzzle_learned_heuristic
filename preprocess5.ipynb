{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Worked on by: Meena Hari and Tarini Singh.\n",
    "\n",
    "We perform data preprocessing using KNearestNeighbors.\n",
    "66 new features are generated.\n",
    "\n",
    "Trained a 1 layer ANN with transformed, higher dimensional \n",
    "dataset (each input consists of the raw board representaion \n",
    "(list of integers from 1 - 16) plus 66 newly generated features).\n",
    "\n",
    "In prog.\n",
    "\n",
    "'''\n",
    "from numba import njit, jit\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from tqdm import tqdm\n",
    "import keras.backend as K\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Conv2D, Flatten, Input\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from keras.models import load_model\n",
    "import keras.losses\n",
    "\n",
    "from constants import *\n",
    "import heuristic as h\n",
    "import io_help as io\n",
    "import neural_net as nn\n",
    "import solver as s\n",
    "\n",
    "NEIGHBORS = 151\n",
    "\n",
    "def load_data(file_name):\n",
    "    \"\"\"\n",
    "    This function reads in training data from a file and returns \n",
    "    the boards in X and their labels in Y as a tuple. \n",
    "    \"\"\"\n",
    "    file = open(file_name, \"r\")\n",
    "    X = []\n",
    "    Y = []\n",
    "    \n",
    "\n",
    "    for string in file: \n",
    "        (board, dist) = io.string_to_board_and_dist(string)\n",
    "        X_temp = np.concatenate((board.reshape(16)), axis=None)\n",
    "        X.append(X_temp)\n",
    "        Y.append(dist)\n",
    "        \n",
    "    file.close()\n",
    "    X_train = np.asarray(X)\n",
    "    Y_train = np.asarray(Y)\n",
    "    return(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/meena/miniconda3/lib/python3.7/site-packages/IPython/core/magics/pylab.py:160: UserWarning: pylab import has clobbered these variables: ['random']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n",
      "  \"\\n`%matplotlib` prevents importing * from pylab and numpy\"\n"
     ]
    }
   ],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(93844, 16)\n"
     ]
    }
   ],
   "source": [
    "# Load dataset. \n",
    "# X: board inputs, Y: true output.\n",
    "(X_train,Y_train) = load_data('Uncombined Data Files/meena_5_19_2020_93844.txt')\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generates additional features.\n",
    "# X: the input data file.\n",
    "# X_train: the original training data file (not transformed).\n",
    "\n",
    "\n",
    "#def gen_features (X, X_train, knn_model):\n",
    "\n",
    "#def gen_features(X, neighs, X_train, knn_model):\n",
    "@njit\n",
    "def gen_features(X, neighs, X_train):\n",
    "    data_arr = np.zeros((len(X), 66), dtype=float64)\n",
    "    man_ham_2D = np.zeros((len(X), 66), dtype=float64)\n",
    "    one_hot_2D = np.zeros((len(X), 288), dtype=float64)\n",
    "    #pred = knn_model.kneighbors(X)\n",
    "    \n",
    "    #for i in tqdm(range(len(X))):\n",
    "    for i in range(X.shape[0]):\n",
    "        row = X[i]\n",
    "        # Grabs the rows in X corresponding to 50 nearest neighbors of X[i].\n",
    "        # pred[1][i] contains a list of the indices of the 50 nearest neighbors.\n",
    "        data = X_train[neighs[i]]\n",
    "        # Divide X[i] by each of its neighbors. div should be a \n",
    "        # 151 x 16 matrix, i.e. div[j] = X[i] / X[j].\n",
    "        div = (row / data)\n",
    "        # Subtract X[i] by each of its neighbors. diff should be a \n",
    "        # 151 x 16 dimension matrix.\n",
    "        diff = (row - data)\n",
    "        \n",
    "        \n",
    "        # concat is a 151 x 32 matrix.\n",
    "        concat = np.zeros((NEIGHBORS, 32))\n",
    "        concat[:, :16] = div\n",
    "        concat[:, 16:] = diff\n",
    "        #concat = np.concatenate([div, diff], axis = 1)\n",
    "        \n",
    "        # means is a 151 x 32 matrix.\n",
    "        # std is a 151 x 32 matrix.\n",
    "        means, stds = np.nanmean(concat, axis = 0), np.nanstd(concat, axis = 0)\n",
    "        # Populate data_arr with newly generated features.\n",
    "        data_arr[i, :means.shape[0]] = means\n",
    "        data_arr[i, means.shape[0]:means.shape[0] + stds.shape[0]] = stds\n",
    "        data_arr[i, -1] = np.nanmean(pred[0][i])\n",
    "        data_arr[i, -2] = np.nanstd(pred[0][i])\n",
    "        \n",
    "        \n",
    "        # Hamming distances\n",
    "        \"\"\"\n",
    "        computes the hamming metric from the board to the solved state and returns \n",
    "        it\n",
    "        trash is merely to get to conform to standard metric implementation\n",
    "        https://en.wikipedia.org/wiki/Hamming_distance\n",
    "        \"\"\"\n",
    "        ham_dist = 0\n",
    "        board = row.reshape(4,4)\n",
    "        for i in range (0, SIZE):\n",
    "            for j in range (0, SIZE):\n",
    "                # check of (2 * (SIZE - 1)) ensures that do not check \n",
    "                val = board[i,j]\n",
    "                if i + j != (2 * (SIZE - 1)) and (i,j) != (((val-1) // SIZE), ((val-1) % SIZE)):\n",
    "                    ham_dist += 1\n",
    "        \n",
    "        \n",
    "        # Manhattan Distance\n",
    "        \"\"\"\n",
    "        computes the manhattan metric from the board to the solved stateand returns \n",
    "        it\n",
    "        trash is merely to get to conform to standard metric implementation\n",
    "        https://en.wikipedia.org/wiki/Taxicab_geometry\n",
    "        \"\"\"\n",
    "        man_dist = 0\n",
    "        for i in range (0, SIZE):\n",
    "            for j in range (0, SIZE):\n",
    "                val = board[i,j]\n",
    "                (i_right, j_right) = (((val-1) // SIZE), ((val-1) % SIZE))\n",
    "                if board[i,j] != SIZE ** 2:\n",
    "                    man_dist += abs(i - i_right) + abs(j - j_right)\n",
    "        \n",
    "        man_ham_2D[i,0] = man_dist\n",
    "        man_ham_2D[i,1] = ham_dist\n",
    "        #one_hot_2D[i] = nn.get_rep_2(row.reshape(4,4))\n",
    "        \n",
    "    # Concatenate generated features to the original dataset.\n",
    "    #return np.concatenate([one_hot_2D, man_ham_2D, data_arr], axis=1)\n",
    "    return (man_ham_2D, data_arr)\n",
    "    #return np.concatenate([man_ham_2D, data_arr], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_model = NearestNeighbors(n_neighbors=NEIGHBORS, n_jobs = -1).fit(X_train,Y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = knn_model.kneighbors(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypingError",
     "evalue": "Failed in nopython mode pipeline (step: nopython frontend)\nInvalid use of Function(<function nanmean at 0x10dc43ea0>) with argument(s) of type(s): (array(float64, 2d, C), axis=Literal[int](0))\n * parameterized\nIn definition 0:\n    TypeError: np_nanmean() got an unexpected keyword argument 'axis'\n    raised from /Users/meena/miniconda3/lib/python3.7/site-packages/numba/typing/templates.py:539\nIn definition 1:\n    TypeError: np_nanmean() got an unexpected keyword argument 'axis'\n    raised from /Users/meena/miniconda3/lib/python3.7/site-packages/numba/typing/templates.py:539\nThis error is usually caused by passing an argument of a type that is unsupported by the named function.\n[1] During: resolving callee type: Function(<function nanmean at 0x10dc43ea0>)\n[2] During: typing of call at <ipython-input-25-cdaf72806533> (38)\n\n\nFile \"<ipython-input-25-cdaf72806533>\", line 38:\ndef gen_features(X, neighs, X_train):\n    <source elided>\n        # std is a 151 x 32 matrix.\n        means, stds = np.nanmean(concat, axis = 0), np.nanstd(concat, axis = 0)\n        ^\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypingError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-e19ed00b0571>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#X_train_2 = gen_features(X_train, pred[1], X_train)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;34m(\u001b[0m\u001b[0mman_ham_2D\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_arr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/numba/dispatcher.py\u001b[0m in \u001b[0;36m_compile_for_args\u001b[0;34m(self, *args, **kws)\u001b[0m\n\u001b[1;32m    399\u001b[0m                 \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpatch_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    400\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 401\u001b[0;31m             \u001b[0merror_rewrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'typing'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    402\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUnsupportedError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    403\u001b[0m             \u001b[0;31m# Something unsupported is present in the user code, add help info\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/numba/dispatcher.py\u001b[0m in \u001b[0;36merror_rewrite\u001b[0;34m(e, issue_type)\u001b[0m\n\u001b[1;32m    342\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 344\u001b[0;31m                 \u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    345\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m         \u001b[0margtypes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/numba/six.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(tp, value, tb)\u001b[0m\n\u001b[1;32m    666\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    667\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 668\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    669\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    670\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypingError\u001b[0m: Failed in nopython mode pipeline (step: nopython frontend)\nInvalid use of Function(<function nanmean at 0x10dc43ea0>) with argument(s) of type(s): (array(float64, 2d, C), axis=Literal[int](0))\n * parameterized\nIn definition 0:\n    TypeError: np_nanmean() got an unexpected keyword argument 'axis'\n    raised from /Users/meena/miniconda3/lib/python3.7/site-packages/numba/typing/templates.py:539\nIn definition 1:\n    TypeError: np_nanmean() got an unexpected keyword argument 'axis'\n    raised from /Users/meena/miniconda3/lib/python3.7/site-packages/numba/typing/templates.py:539\nThis error is usually caused by passing an argument of a type that is unsupported by the named function.\n[1] During: resolving callee type: Function(<function nanmean at 0x10dc43ea0>)\n[2] During: typing of call at <ipython-input-25-cdaf72806533> (38)\n\n\nFile \"<ipython-input-25-cdaf72806533>\", line 38:\ndef gen_features(X, neighs, X_train):\n    <source elided>\n        # std is a 151 x 32 matrix.\n        means, stds = np.nanmean(concat, axis = 0), np.nanstd(concat, axis = 0)\n        ^\n"
     ]
    }
   ],
   "source": [
    "#X_train_2 = gen_features(X_train, pred[1], X_train)\n",
    "(man_ham_2D, data_arr) = gen_features(X_train, pred[1], X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_2 = np.concatenate([man_ham_2D, data_arr], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [1.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [1.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.        , 0.        , 0.        , ..., 0.12507262, 1.06638986,\n",
       "        8.61935475],\n",
       "       [0.        , 0.        , 0.        , ..., 0.13267004, 1.14509462,\n",
       "        8.38873516],\n",
       "       [0.        , 0.        , 0.        , ..., 0.1328004 , 1.10117625,\n",
       "        8.63494327]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shift_mse(y_true, y_pred):\n",
    "    \"\"\"custom loss functions\"\"\"\n",
    "    loss = (1 + 6/(1 + K.exp(-(y_pred - y_true)))) * K.square(y_pred - y_true)\n",
    "    loss = K.mean(loss, axis = 1)\n",
    "    return loss\n",
    "\n",
    "\n",
    "def exp_loss_2(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Custom loss function. \n",
    "    \"\"\"\n",
    "    loss = K.exp((y_pred - y_true))\n",
    "    loss = loss + K.square(y_pred - y_true)\n",
    "    loss = K.mean(loss, axis = 1)\n",
    "\n",
    "    return loss\n",
    "    \n",
    "keras.losses.shift_mse = shift_mse\n",
    "keras.losses.exp_loss_2 = exp_loss_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def luka_model (X, Y):\n",
    "    # Build Model\n",
    "    model = Sequential()\n",
    "\n",
    "    # Input Layer\n",
    "    i = Input(shape = (16*2*2+2+(256 + 32 + 2),))\n",
    "    x_1 = Dense(16*2*2+2+(256 + 32 + 2), activation='relu')(i)\n",
    "    x_2 = Dropout(0.1)(x_1)\n",
    "    x_3 = Dense(356, activation='relu')(x_2)\n",
    "    x_4 = Dropout(0.1)(x_3)\n",
    "    x_5 = Dense(17, activation='relu')(x_4)\n",
    "    o = Dense(1, activation='linear')(x_1)\n",
    "    model = Model(i,o)\n",
    "\n",
    "    # Define the optimizer and loss function\n",
    "    model.compile(optimizer='adam', loss=exp_loss_2, metrics=['accuracy'])\n",
    "\n",
    "    # You can also define a custom loss function\n",
    "    # model.compile(optimizer='adam', loss=custom_loss)\n",
    "\n",
    "    # Train \n",
    "    model.fit(X, Y, epochs=15)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# Build Model\n",
    "model = Sequential()\n",
    "\n",
    "# Input Layer\n",
    "model.add(Dense(units=(16*2*2+2+16), input_dim=(16*2*2+2+16), activation='relu'))\n",
    "model.add(Dropout(0.1))\n",
    "\n",
    "# Hidden Layers\n",
    "model.add(Dense(units=66+16, activation='relu'))\n",
    "\n",
    "# Output Layer\n",
    "model.add(Dense(units=1, activation='linear'))\n",
    "\n",
    "# Define the optimizer and loss function\n",
    "#model.compile(optimizer='adam', loss='mse', metrics=['accuracy'])\n",
    "model.compile(optimizer='adam', loss=shift_mse, metrics=['accuracy'])\n",
    "\n",
    "# You can also define a custom loss function\n",
    "# model.compile(optimizer='adam', loss=custom_loss)\n",
    "\n",
    "# Train \n",
    "model.fit(X_train_2, Y_train, epochs=20)\n",
    "\n",
    "# Test\n",
    "#score = model.evaluate(X_test, Y_test)\n",
    "\n",
    "#print(score)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10047/10047 [00:05<00:00, 1705.58it/s]\n"
     ]
    }
   ],
   "source": [
    "# Load test dataset. \n",
    "# X_test: board inputs, Y_test: true output.\n",
    "(X_test,Y_test) = load_data('Uncombined Data Files/Yasmin_5_19_10048.txt')\n",
    "\n",
    "# Transform X_test to higher dimension.\n",
    "X_test_2 = gen_features (X_test, X_train, knn_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "10047/10047 [==============================] - 1s 71us/step - loss: 20.8628 - accuracy: 0.2501\n",
      "Epoch 2/15\n",
      "10047/10047 [==============================] - 0s 47us/step - loss: 6.9038 - accuracy: 0.3425\n",
      "Epoch 3/15\n",
      "10047/10047 [==============================] - 0s 49us/step - loss: 5.6089 - accuracy: 0.3629\n",
      "Epoch 4/15\n",
      "10047/10047 [==============================] - 0s 50us/step - loss: 4.6231 - accuracy: 0.3744\n",
      "Epoch 5/15\n",
      "10047/10047 [==============================] - 1s 66us/step - loss: 3.8167 - accuracy: 0.3957\n",
      "Epoch 6/15\n",
      "10047/10047 [==============================] - 1s 55us/step - loss: 3.1482 - accuracy: 0.4097\n",
      "Epoch 7/15\n",
      "10047/10047 [==============================] - 0s 50us/step - loss: 2.6632 - accuracy: 0.4303\n",
      "Epoch 8/15\n",
      "10047/10047 [==============================] - 0s 50us/step - loss: 2.2559 - accuracy: 0.4809\n",
      "Epoch 9/15\n",
      "10047/10047 [==============================] - 0s 49us/step - loss: 1.9696 - accuracy: 0.4828\n",
      "Epoch 10/15\n",
      "10047/10047 [==============================] - 1s 65us/step - loss: 1.7632 - accuracy: 0.5143\n",
      "Epoch 11/15\n",
      "10047/10047 [==============================] - 1s 73us/step - loss: 1.6126 - accuracy: 0.5231\n",
      "Epoch 12/15\n",
      "10047/10047 [==============================] - 1s 53us/step - loss: 1.5135 - accuracy: 0.5311\n",
      "Epoch 13/15\n",
      "10047/10047 [==============================] - 1s 54us/step - loss: 1.4179 - accuracy: 0.5465\n",
      "Epoch 14/15\n",
      "10047/10047 [==============================] - 1s 52us/step - loss: 1.3422 - accuracy: 0.5600\n",
      "Epoch 15/15\n",
      "10047/10047 [==============================] - 1s 56us/step - loss: 1.2746 - accuracy: 0.5794\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10047/10047 [00:08<00:00, 1195.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ TRUCATION: ------\n",
      "Avg distance overestimated:  1.0057803468208093\n",
      "Avg distance underestimated:  0.595705894267774\n",
      "E_admiss:  0.017219070369264455\n",
      "E_out:  0.5658405494177366\n",
      "Avg distance over Manhattan:  4.451914270012823\n",
      "Avg distance under Manhattan:  1.0125414976023608\n",
      "Percent over Manhattan:  0.5433462725191599\n",
      "Percent under Manhattan:  0.269831790584254\n",
      "\n",
      "\n",
      "------ ROUNDED: ------\n",
      "Avg distance overestimated:  1.0059022\n",
      "Avg distance underestimated:  0.17210247\n",
      "E_admiss:  0.11804518761819449\n",
      "E_out:  0.25868418433363194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dist_over_i = []\n",
    "misclass_i = 0\n",
    "dist_under_i = []\n",
    "dist_over_man_i = []\n",
    "dist_under_man_i = []\n",
    "\n",
    "dist_over_r = []\n",
    "misclass_r = 0\n",
    "dist_under_r = []\n",
    "\n",
    "model = luka_model(X_test_2, Y_test)\n",
    "\n",
    "for i in tqdm(range(len(X_test))):\n",
    "    nn_heur_i = int(model.predict(X_test_2[i:(i+1),:]))\n",
    "    nn_heur_r = np.around(model.predict(X_test_2[i:(i+1),:]))\n",
    "    man_heur = h.manhattan(X_test[i].reshape(4,4), model)\n",
    "    y = Y_test[i]\n",
    "    \n",
    "    ### TRUNCATE ###\n",
    "    if (nn_heur_i > y):\n",
    "        dist_over_i.append(nn_heur_i - y)\n",
    "    \n",
    "    if (nn_heur_i <= y):\n",
    "        dist_under_i.append(y - nn_heur_i)\n",
    "    \n",
    "    if (nn_heur_i != y):\n",
    "        misclass_i += 1\n",
    "    \n",
    "    if (nn_heur_i > man_heur):\n",
    "        dist_over_man_i.append(nn_heur_i - man_heur)\n",
    "        \n",
    "    if (nn_heur_i < man_heur):\n",
    "        dist_under_man_i.append(man_heur - nn_heur_i)\n",
    "    \n",
    "        \n",
    "    ##### ROUND ##### \n",
    "    if (nn_heur_r > y):\n",
    "        dist_over_r.append(nn_heur_r - y)\n",
    "    \n",
    "    if (nn_heur_r <= y):\n",
    "        dist_under_r.append(y - nn_heur_r)\n",
    "    \n",
    "    if (nn_heur_r != y):\n",
    "        misclass_r += 1\n",
    "    \n",
    "avg_dist_over_i = np.mean(np.asarray(dist_over_i))\n",
    "avg_dist_under_i = np.mean(np.asarray(dist_under_i))\n",
    "out_sample_error_i = misclass_i / len(X_test)\n",
    "avg_dist_over_man_i = np.mean(np.asarray(dist_over_man_i))\n",
    "avg_dist_under_man_i = np.mean(np.asarray(dist_under_man_i))\n",
    "\n",
    "avg_dist_over_r = np.mean(np.asarray(dist_over_r))\n",
    "avg_dist_under_r = np.mean(np.asarray(dist_under_r))\n",
    "out_sample_error_r = misclass_r / len(X_test)\n",
    " \n",
    "print(\"------ TRUCATION: ------\")\n",
    "print(\"Avg distance overestimated: \", avg_dist_over_i)\n",
    "print(\"Avg distance underestimated: \", avg_dist_under_i)\n",
    "print(\"E_admiss: \", len(dist_over_i)/len(X_test))\n",
    "print(\"E_out: \", out_sample_error_i)\n",
    "print(\"Avg distance over Manhattan: \", avg_dist_over_man_i)\n",
    "print(\"Avg distance under Manhattan: \", avg_dist_under_man_i)\n",
    "print(\"Percent over Manhattan: \", len(dist_over_man_i)/len(X_test))\n",
    "print(\"Percent under Manhattan: \", len(dist_under_man_i)/len(X_test))\n",
    "print(\"\\n\")\n",
    "print(\"------ ROUNDED: ------\")\n",
    "print(\"Avg distance overestimated: \", avg_dist_over_r)\n",
    "print(\"Avg distance underestimated: \", avg_dist_under_r)\n",
    "print(\"E_admiss: \", len(dist_over_r)/len(X_test))\n",
    "print(\"E_out: \", out_sample_error_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"one_HAWT_356_17_nn.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# DON\\'T HAVE TO RUN THIS CELL AGAIN, only to transform Yasmin_5_16_40360.txt.\\n\\n(X,Y) = load_data(\\'Uncombined Data Files/Yasmin_5_16_40360.txt\\')\\nknn_model_all = NearestNeighbors(n_neighbors=50, n_jobs = -1).fit(X,Y)\\nX_2 = gen_features(X, X, knn_model_all)\\nX_Y = np.column_stack((X_2, Y))\\nnp.savetxt(\"Yasmin_40360_50knn_Trans.csv\", X_Y, delimiter=\\',\\')\\n'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# DON'T HAVE TO RUN THIS CELL AGAIN, only to transform Yasmin_5_16_40360.txt.\n",
    "\n",
    "(X,Y) = load_data('Uncombined Data Files/Yasmin_5_16_40360.txt')\n",
    "knn_model_all = NearestNeighbors(n_neighbors=50, n_jobs = -1).fit(X,Y)\n",
    "X_2 = gen_features(X, X, knn_model_all)\n",
    "X_Y = np.column_stack((X_2, Y))\n",
    "np.savetxt(\"Yasmin_40360_50knn_Trans.csv\", X_Y, delimiter=',')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndef heur_boi(board, model):\\n    \"\"\"\\n    This function takes in a board and a trained NN model and returns\\n    the heuristic the model predicts.\\n    \"\"\"\\n    return 0\\n    #[[pred]] = model.predict(board)\\n    #return round(pred)\\n'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def string_to_test_info(string):\n",
    "    \"\"\"\n",
    "    given a string containing the standard form of test info, returns tuple of \n",
    "    board, number of states to solution, time, and lenght of solution\n",
    "    \"\"\"\n",
    "    split = string.split(\"!\")\n",
    "    board = io.string_to_board(split[0])\n",
    "    n_states = int(split[1])\n",
    "    time = float(split[2])\n",
    "    sol_len = int(split[3])\n",
    "    return (board, n_states, time, sol_len)\n",
    "\n",
    "\n",
    "def load_boards(filename):\n",
    "    \"\"\"\n",
    "    given name of file containing test boards, loads all test boards\n",
    "    \"\"\"\n",
    "    file = open(filename, \"r\")\n",
    "\n",
    "    boards = []\n",
    "    n_states = []\n",
    "    times = []\n",
    "    dists = []\n",
    "\n",
    "    for line in file:\n",
    "        (board, c_states, c_time, sol_len) = string_to_test_info(line)\n",
    "        boards.append(board)\n",
    "        n_states.append(c_states)\n",
    "        times.append(c_time)\n",
    "        dists.append(sol_len)\n",
    "\n",
    "    return (boards, n_states, times, dists)\n",
    "\n",
    "def run_testing(data_file, model, h_func):\n",
    "    \"\"\"\n",
    "    given a data_file containing testing data, a model, and heuristic function\n",
    "    for said model, computes average number of states to solution, number to \n",
    "    times solution length is non-optimal, and average estimates of solution \n",
    "    lengths\n",
    "    \"\"\"\n",
    "    (boards, n_states, times, dists) = load_boards(data_file)\n",
    "\n",
    "    cust_states = []\n",
    "    cust_wrong = 0\n",
    "    cust_distance = []\n",
    "\n",
    "    for i in tqdm(range(len(boards))):\n",
    "        #(c_states, c_time, sol_path) = s.solve(boards[i], h_func, model)\n",
    "        (c_states, c_time, sol_path) = s.solve(boards[i], h_func, model)\n",
    "        cust_states.append(c_states)\n",
    "        sol_len = len(sol_path) - 1\n",
    "        if not (sol_len == dists[i]):\n",
    "            cust_wrong += 1\n",
    "        cust_distance.append(sol_len)\n",
    "\n",
    "    print(\"average number of states explored to find solution:\")\n",
    "    print(\"\\tfor learned model: \" + str(np.mean(cust_states)))\n",
    "    print(\"\\tfor manhattan distance: \" + str(np.mean(n_states)))\n",
    "    print(\"----------------------------------------------------\")\n",
    "    print(\"solution was non-optimal \" + str(cust_wrong / NUM_TEST_BOARDS * 100) + \"% of the time\")\n",
    "    print(\"----------------------------------------------------\")\n",
    "    print(\"average length of solution path was:\")\n",
    "    print(\"\\tfor learned model: \" + str(np.mean(cust_distance)))\n",
    "    print(\"\\tfor manhattan distance: \" + str(np.mean(dists)))\n",
    "'''\n",
    "def heur_boi(board, model):\n",
    "    \"\"\"\n",
    "    This function takes in a board and a trained NN model and returns\n",
    "    the heuristic the model predicts.\n",
    "    \"\"\"\n",
    "    return 0\n",
    "    #[[pred]] = model.predict(board)\n",
    "    #return round(pred)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic = {}\n",
    "def heur_boi(board, model):\n",
    "    b1 = board.reshape(16)\n",
    "    man = np.array(h.manhattan(b1.reshape(4,4), None))\n",
    "    ham = np.array(h.hamming(b1.reshape(4,4), None))\n",
    "    \n",
    "    b1_str = np.array_str(b1)\n",
    "    #b2 = np.concatenate((b1, man, ham), axis=None)\n",
    "    #b2_str = np.array_str(b2)\n",
    "    \n",
    "    if b1_str in dic:\n",
    "        return dic.get(b1_str)\n",
    "    else:\n",
    "        # transform board\n",
    "        X_2 = gen_features(np.asarray([b1]), X_train, knn_model)\n",
    "        [[pred]] = model.predict(X_2[0].reshape(1,-1))\n",
    "        dic[b1_str] = int(pred)\n",
    "        return dic[b1_str]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 10/15 [12:08<04:41, 56.25s/it]"
     ]
    }
   ],
   "source": [
    "run_testing('baby_test.txt', model, heur_boi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(np.zeros((1,82)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(np.arange(82).T).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.arange(82)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.asarray([np.arange(82)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t2 = gen_features(np.asarray([np.arange(16)]), X_train, knn_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t3 = gen_features(np.asarray([np.arange(16)]), X_train, knn_model)\n",
    "[[pred]] = model.predict(t3[0].reshape(1,-1))\n",
    "print(round(pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array([2,6,3,4,12,5,10,15,1,14,16,8,13,7,9,11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t3 = gen_features(np.asarray([np.array([5,7,16,2,6,14,12,1,9,3,11,15,13,10,8,4])]), X_train, knn_model)\n",
    "[[pred]] = model.predict(t3[0].reshape(1,-1))\n",
    "print(round(pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.calc_displacements(np.array([5,7,16,2,6,14,12,1,9,3,11,15,13,10,8,4]).reshape(4,4)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t4 = np.zeros()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 137 ms, sys: 2.61 ms, total: 140 ms\n",
      "Wall time: 139 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def dummy(arr):\n",
    "    for i in range(100000):\n",
    "        arr = arr / 16\n",
    "    return arr\n",
    "\n",
    "%time dummy(np.arange(16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit\n",
    "def dummy2(arr):\n",
    "    for i in range(100000):\n",
    "        arr = arr / 16.0\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 136 ms, sys: 2.51 ms, total: 138 ms\n",
      "Wall time: 137 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time dummy2(np.arange(16.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 14.8 ms, sys: 308 µs, total: 15.1 ms\n",
      "Wall time: 15 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time dummy2(np.arange(16.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def monte_carlo(n):\n",
    "    acc = 0\n",
    "    for i in range(n):\n",
    "        x = random.random()\n",
    "        y = random.random()\n",
    "        if (x**2 + y**2) < 1.0:\n",
    "            acc += 1\n",
    "    return 4.0 * acc / n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.84 ms, sys: 387 µs, total: 5.23 ms\n",
      "Wall time: 4.92 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3.1792"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time dummy(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 89.6 ms, sys: 2.18 ms, total: 91.8 ms\n",
      "Wall time: 91.2 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3.1276"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mc2 = jit()(monte_carlo)\n",
    "\n",
    "%time mc2(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 183 µs, sys: 1 µs, total: 184 µs\n",
      "Wall time: 186 µs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3.1252"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time mc2(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.76 ms, sys: 2 µs, total: 1.77 ms\n",
      "Wall time: 1.77 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3.13416"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'type'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-76-f5fca8ea340a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'type'"
     ]
    }
   ],
   "source": [
    "np.zeros(16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.0"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float64(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
