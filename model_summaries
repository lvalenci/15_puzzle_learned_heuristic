# Model Summaries
-- exp_loss_2: architecture is 256 input layer, 16 unit dense layer with ReLu activiation, single output unit with linear activation. Trained for 10 epochs with Adam as the optimizer and using exp_loss (loss = K.exp((y_pred - y_true)) / 10;loss = loss + K.square((y_pred - y_true) / 2);loss = K.mean(loss, axis = 1)). Resulted in prediction being less than manhattan distance 6.88% of the time and greater than actual distance 17.67% of the time.
-- nn_exp_loss_2b: architecture is 256 input layer, 256 unit dense layer with ReLu activiation, single output unit with linear activation. Trained for 10 epochs with Adam as the optimizer and using exp_loss_2 (loss = K.exp((y_pred - y_true)) / 2;loss = loss + K.square(y_pred - y_true);loss = K.mean(loss, axis = 1)). Resulted in prediction less than manhattan distance 3.688% of the time and greater than acutal distance 14.467% of the time
-- nn_exp_loss_2c: architecture is 256 input layer, 256 unit dense layer with ReLu activiation, 16 unit dense layer with ReLu activation, single output unit with linear activation. Trained for 15 epochs with Adam as the optimizer and using exp_loss_2 (loss = K.exp((y_pred - y_true)) / 2;loss = loss + K.square(y_pred - y_true);loss = K.mean(loss, axis = 1)). Resulted in prediction less than manhattan distance 5.3% of time and greater than actual distance 13% of the time