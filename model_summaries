# Model Summaries
-- exp_loss_2: architecture is 256 input layer, 16 unit dense layer with ReLu activiation, single output unit with linear activation. Trained for 10 epochs with Adam as the optimizer and using exp_loss (loss = K.exp((y_pred - y_true)) / 10;loss = loss + K.square((y_pred - y_true) / 2);loss = K.mean(loss, axis = 1)). Resulted in prediction being less than manhattan distance 6.88% of the time and greater than actual distance 17.67% of the time.
-- nn_exp_loss_2b: architecture is 256 input layer, 256 unit dense layer with ReLu activiation, single output unit with linear activation. Trained for 10 epochs with Adam as the optimizer and using exp_loss_2 (loss = K.exp((y_pred - y_true)) / 2;loss = loss + K.square(y_pred - y_true);loss = K.mean(loss, axis = 1)). Results TBD