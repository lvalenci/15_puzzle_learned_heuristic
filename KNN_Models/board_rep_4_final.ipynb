{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Worked on by: Meena Hari and Tarini Singh.\n",
    "\n",
    "We perform data preprocessing using KNearestNeighbors.\n",
    "66 new features are generated using the KNN. \n",
    "\n",
    "The board is also one-hot encoded, and\n",
    "x/y displacements to the solved configation and\n",
    "Manhattan and Hamming distances are included as features.\n",
    "\n",
    "In total, the input feature length is transformed from 16\n",
    "to 356.\n",
    "\n",
    "Trained a 2 layer ANN with the transformed dataset.\n",
    "'''\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from tqdm import tqdm\n",
    "import keras.backend as K\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Conv2D, Flatten, Input\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from keras.models import load_model\n",
    "import keras.losses\n",
    "\n",
    "from constants import *\n",
    "import heuristic as h\n",
    "import io_help as io\n",
    "import neural_net as nn\n",
    "import solver as s\n",
    "\n",
    "def load_data(file_name):\n",
    "    \"\"\"\n",
    "    This function reads in training data from a file and returns \n",
    "    the boards in X and their labels in Y as a tuple. \n",
    "    \"\"\"\n",
    "    file = open(file_name, \"r\")\n",
    "    X = []\n",
    "    Y = []\n",
    "    \n",
    "\n",
    "    for string in file: \n",
    "        (board, dist) = io.string_to_board_and_dist(string)\n",
    "        X_temp = np.concatenate((board.reshape(16)), axis=None)\n",
    "        X.append(X_temp)\n",
    "        Y.append(dist)\n",
    "        \n",
    "    file.close()\n",
    "    X_train = np.asarray(X)\n",
    "    Y_train = np.asarray(Y)\n",
    "    return(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(395715, 16)\n"
     ]
    }
   ],
   "source": [
    "# Load dataset. \n",
    "# X: board inputs, Y: true output.\n",
    "(X_train,Y_train) = load_data('All_Data.txt')\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generates additional features.\n",
    "# X: the input data file.\n",
    "# X_train: the original training data file (not transformed).\n",
    "def gen_features (X, X_train, knn_model):\n",
    "    data_arr = np.zeros([len(X), (16)*2*2 + 2])\n",
    "    man_ham_2D = np.zeros([len(X), 2])\n",
    "    one_hot_2D = np.zeros([len(X), 256+32])\n",
    "    pred = knn_model.kneighbors(X)\n",
    "    \n",
    "\n",
    "    for i in range(len(X)):\n",
    "        row = X[i]\n",
    "        # Grabs the rows in X corresponding to 35 nearest neighbors of X[i].\n",
    "        # pred[1][i] contains a list of the indices of the 35 nearest neighbors of X[i].\n",
    "        data = X_train[pred[1][i]]\n",
    "        # Divide X[i] by each of its neighbors. div should be a \n",
    "        # 35 x 16 matrix, i.e. div[j] = X[i] / X[j].\n",
    "        div = (row / data)\n",
    "        # Subtract X[i] by each of its neighbors. diff should be a \n",
    "        # 35 x 16 dimension matrix.\n",
    "        diff = (row - data)\n",
    "        # concat is a 35 x 32 matrix.\n",
    "        concat = np.concatenate([div, diff], axis = 1)\n",
    "        # means is a 35 x 32 matrix.\n",
    "        # std is a 35 x 32 matrix.\n",
    "        means, stds = np.nanmean(concat, axis = 0), np.nanstd(concat, axis = 0)\n",
    "        # Populate data_arr with newly generated features.\n",
    "        data_arr[i, :len(means)] = means\n",
    "        data_arr[i, len(means):len(means) + len(stds)] = stds\n",
    "        # Add average and standard deviation of distance away from 35 neighbors.\n",
    "        data_arr[i, -1] = np.nanmean(pred[0][i])\n",
    "        data_arr[i, -2] = np.nanstd(pred[0][i])\n",
    "        \n",
    "        # Calculate Manhattan/Hamming distances.\n",
    "        man = h.manhattan(row.reshape(4,4), None)\n",
    "        ham = h.hamming(row.reshape(4,4), None)\n",
    "        man_ham_2D[i,0] = man\n",
    "        man_ham_2D[i,1] = ham\n",
    "        # Calculate one-hot encoding of the sample.\n",
    "        one_hot_2D[i] = nn.get_rep_2(row.reshape(4,4))\n",
    "        \n",
    "    # Concatenate all features plus one-hot encoded dataset.\n",
    "    return np.concatenate([data_arr, one_hot_2D, man_ham_2D], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_model = NearestNeighbors(n_neighbors=35, n_jobs = -1).fit(X_train,Y_train)\n",
    "X_train_2 = gen_features(X_train, X_train, knn_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(395715, 356)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shift_mse(y_true, y_pred):\n",
    "    \"\"\"custom loss functions\"\"\"\n",
    "    loss = (1 + 6/(1 + K.exp(-(y_pred - y_true)))) * K.square(y_pred - y_true)\n",
    "    loss = K.mean(loss, axis = 1)\n",
    "    return loss\n",
    "\n",
    "\n",
    "def exp_loss_2(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Custom loss function. \n",
    "    \"\"\"\n",
    "    loss = K.exp((y_pred - y_true))\n",
    "    loss = loss + K.square(y_pred - y_true)\n",
    "    loss = K.mean(loss, axis = 1)\n",
    "\n",
    "    return loss\n",
    "    \n",
    "keras.losses.shift_mse = shift_mse\n",
    "keras.losses.exp_loss_2 = exp_loss_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rep_4_model (X, Y):\n",
    "    # Build Model\n",
    "    model = Sequential()\n",
    "\n",
    "    # Input Layer\n",
    "    i = Input(shape = (16*2*2+2+(256 + 32 + 2),))\n",
    "    x_1 = Dense(16*2*2+2+(256 + 32 + 2), activation='relu')(i)\n",
    "    x_2 = Dropout(0.1)(x_1)\n",
    "    x_3 = Dense(356, activation='relu')(x_2)\n",
    "    x_4 = Dropout(0.1)(x_3)\n",
    "    x_5 = Dense(17, activation='relu')(x_4)\n",
    "    o = Dense(1, activation='linear')(x_1)\n",
    "    model = Model(i,o)\n",
    "\n",
    "    # Define the optimizer and loss function\n",
    "    model.compile(optimizer='adam', loss=shift_mse, metrics=['accuracy'])\n",
    "\n",
    "    # Train \n",
    "    model.fit(X, Y, epochs=15)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test dataset. X_test: board inputs, Y_test: true output.\n",
    "(X_test,Y_test) = load_data('All_Data.txt')\n",
    "\n",
    "# Transform X_test to higher dimension.\n",
    "X_test_2 = gen_features (X_test, X_train, knn_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Calculate in-sample performance metrics.\n",
    "\n",
    "# Store values due to truncation of the model's prediction.\n",
    "dist_over_i = []\n",
    "misclass_i = 0\n",
    "dist_under_i = []\n",
    "dist_over_man_i = []\n",
    "dist_under_man_i = []\n",
    "\n",
    "# Store values due to rounding of the model's prediction.\n",
    "dist_over_r = []\n",
    "misclass_r = 0\n",
    "dist_under_r = []\n",
    "\n",
    "model = rep_4_model(X_test_2, Y_test)\n",
    "\n",
    "for i in tqdm(range(len(X_test))):\n",
    "    nn_heur_i = int(model.predict(X_test_2[i:(i+1),:]))\n",
    "    nn_heur_r = np.around(model.predict(X_test_2[i:(i+1),:]))\n",
    "    man_heur = h.manhattan(X_test[i].reshape(4,4), model)\n",
    "    y = Y_test[i]\n",
    "    \n",
    "    ### TRUNCATE ###\n",
    "    if (nn_heur_i > y):\n",
    "        dist_over_i.append(nn_heur_i - y)\n",
    "    \n",
    "    if (nn_heur_i <= y):\n",
    "        dist_under_i.append(y - nn_heur_i)\n",
    "    \n",
    "    if (nn_heur_i != y):\n",
    "        misclass_i += 1\n",
    "    \n",
    "    if (nn_heur_i > man_heur):\n",
    "        dist_over_man_i.append(nn_heur_i - man_heur)\n",
    "        \n",
    "    if (nn_heur_i < man_heur):\n",
    "        dist_under_man_i.append(man_heur - nn_heur_i)\n",
    "    \n",
    "        \n",
    "    ##### ROUND ##### \n",
    "    if (nn_heur_r > y):\n",
    "        dist_over_r.append(nn_heur_r - y)\n",
    "    \n",
    "    if (nn_heur_r <= y):\n",
    "        dist_under_r.append(y - nn_heur_r)\n",
    "    \n",
    "    if (nn_heur_r != y):\n",
    "        misclass_r += 1\n",
    "    \n",
    "avg_dist_over_i = np.mean(np.asarray(dist_over_i))\n",
    "avg_dist_under_i = np.mean(np.asarray(dist_under_i))\n",
    "out_sample_error_i = misclass_i / len(X_test)\n",
    "avg_dist_over_man_i = np.mean(np.asarray(dist_over_man_i))\n",
    "avg_dist_under_man_i = np.mean(np.asarray(dist_under_man_i))\n",
    "\n",
    "avg_dist_over_r = np.mean(np.asarray(dist_over_r))\n",
    "avg_dist_under_r = np.mean(np.asarray(dist_under_r))\n",
    "out_sample_error_r = misclass_r / len(X_test)\n",
    " \n",
    "print(\"------ TRUCATION: ------\")\n",
    "print(\"Avg distance overestimated: \", avg_dist_over_i)\n",
    "print(\"Avg distance underestimated: \", avg_dist_under_i)\n",
    "print(\"E_admiss: \", len(dist_over_i)/len(X_test))\n",
    "print(\"E_out: \", out_sample_error_i)\n",
    "print(\"Avg distance over Manhattan: \", avg_dist_over_man_i)\n",
    "print(\"Avg distance under Manhattan: \", avg_dist_under_man_i)\n",
    "print(\"Percent over Manhattan: \", len(dist_over_man_i)/len(X_test) * 100)\n",
    "print(\"Percent under Manhattan: \", len(dist_under_man_i)/len(X_test) * 100)\n",
    "print(\"\\n\")\n",
    "print(\"------ ROUNDED: ------\")\n",
    "print(\"Avg distance overestimated: \", avg_dist_over_r)\n",
    "print(\"Avg distance underestimated: \", avg_dist_under_r)\n",
    "print(\"E_admiss: \", len(dist_over_r)/len(X_test))\n",
    "print(\"E_out: \", out_sample_error_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def string_to_test_info(string):\n",
    "    \"\"\"\n",
    "    given a string containing the standard form of test info, returns tuple of \n",
    "    board, number of states to solution, time, and lenght of solution\n",
    "    (Function copied from run_testing.py).\n",
    "    \"\"\"\n",
    "    split = string.split(\"!\")\n",
    "    board = io.string_to_board(split[0])\n",
    "    n_states = int(split[1])\n",
    "    time = float(split[2])\n",
    "    sol_len = int(split[3])\n",
    "    return (board, n_states, time, sol_len)\n",
    "\n",
    "\n",
    "def load_boards(filename):\n",
    "    \"\"\"\n",
    "    given name of file containing test boards, loads all test boards\n",
    "    (Function copied from run_testing.py).\n",
    "    \"\"\"\n",
    "    file = open(filename, \"r\")\n",
    "\n",
    "    boards = []\n",
    "    n_states = []\n",
    "    times = []\n",
    "    dists = []\n",
    "\n",
    "    for line in file:\n",
    "        (board, c_states, c_time, sol_len) = string_to_test_info(line)\n",
    "        boards.append(board)\n",
    "        n_states.append(c_states)\n",
    "        times.append(c_time)\n",
    "        dists.append(sol_len)\n",
    "\n",
    "    return (boards, n_states, times, dists)\n",
    "\n",
    "def run_testing(data_file, model, h_func):\n",
    "    \"\"\"\n",
    "    given a data_file containing testing data, a model, and heuristic function\n",
    "    for said model, computes average number of states to solution, number to \n",
    "    times solution length is non-optimal, and average estimates of solution \n",
    "    lengths\n",
    "    (Function copied from run_testing.py).\n",
    "    \"\"\"\n",
    "    (boards, n_states, times, dists) = load_boards(data_file)\n",
    "\n",
    "    cust_states = []\n",
    "    cust_wrong = 0\n",
    "    cust_distance = []\n",
    "\n",
    "    for i in tqdm(range(len(boards))):\n",
    "        (c_states, c_time, sol_path) = s.solve(boards[i], h_func, model)\n",
    "        cust_states.append(c_states)\n",
    "        sol_len = len(sol_path) - 1\n",
    "        if not (sol_len == dists[i]):\n",
    "            cust_wrong += 1\n",
    "        cust_distance.append(sol_len)\n",
    "\n",
    "    print(\"average number of states explored to find solution:\")\n",
    "    print(\"\\tfor learned model: \" + str(np.mean(cust_states)))\n",
    "    print(\"\\tfor manhattan distance: \" + str(np.mean(n_states)))\n",
    "    print(\"----------------------------------------------------\")\n",
    "    print(\"solution was non-optimal \" + str(cust_wrong / NUM_TEST_BOARDS * 100) + \"% of the time\")\n",
    "    print(\"----------------------------------------------------\")\n",
    "    print(\"average length of solution path was:\")\n",
    "    print(\"\\tfor learned model: \" + str(np.mean(cust_distance)))\n",
    "    print(\"\\tfor manhattan distance: \" + str(np.mean(dists)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic = {}\n",
    "def heur_rep_4(board, model):\n",
    "    b1 = board.reshape(16)\n",
    "    \n",
    "    # Calculate Manhattan/Hamming distances.\n",
    "    man = np.array(h.manhattan(b1.reshape(4,4), None))\n",
    "    ham = np.array(h.hamming(b1.reshape(4,4), None))\n",
    "    \n",
    "    b1_str = np.array_str(b1)\n",
    "    \n",
    "    if b1_str in dic:\n",
    "        return dic.get(b1_str)\n",
    "    else:\n",
    "        # Transform board.\n",
    "        X_2 = gen_features(np.asarray([b1]), X_train, knn_model)\n",
    "        [[pred]] = model.predict(X_2[0].reshape(1,-1))\n",
    "        # Memoize prediction.\n",
    "        dic[b1_str] = int(pred)\n",
    "        return dic[b1_str]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "run_testing('Test_boards.txt', model, heur_rep_4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
